{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f821bb-27fa-4292-9d86-181f90d27a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "occlusion_ranges = {\n",
    "    \"low\": (0.2, 0.4),\n",
    "    \"medium\": (0.4, 0.6),\n",
    "    \"high\": (0.6, 0.8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d29f1-e78a-4b3e-bf65-5f2da434fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def load_one_annotation(anno_path):\n",
    "    a = scipy.io.loadmat(anno_path)\n",
    "    # I added the astype int here....\n",
    "    bbox_ = a['record'][0][0][1][0][0][1][0].astype(int)\n",
    "    w = a['record']['size'][0][0][0][0][0][0][0]\n",
    "    h = a['record']['size'][0][0][0][0][1][0][0]\n",
    "    num_obj = len(a['record'][0][0][1][0])\n",
    "    return w, h, bbox_, num_obj != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c62389-e92d-470f-b1a3-86e1b646d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get overlap percentage based on bounding boxes\n",
    "'''\n",
    "def overlap_ratio(occluder_bb, occludee_bb):\n",
    "\n",
    "    #top left and bottom right points\n",
    "    occluder_x1, occluder_y1, occluder_x2, occluder_y2 = occluder_bb\n",
    "    occludee_x1, occludee_y1, occludee_x2, occludee_y2 = occludee_bb\n",
    "\n",
    "    # area of the foreground object\n",
    "    occludee_area = (occludee_x2 - occludee_x1) * (occludee_y2 - occludee_y1)\n",
    "\n",
    "    # area of the background object being covered by the foreground object\n",
    "    overlap_area = max(0, min(occludee_x2, occluder_x2) - max(occludee_x1, occluder_x1)) * max(0, min(occludee_y2, occluder_y2) - max(occludee_y1, occluder_y1))\n",
    "\n",
    "    # overlap over the total background object area\n",
    "    return overlap_area / occludee_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a0873-b634-49dd-a8e1-1965c12dfb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "'''\n",
    "Get a list of randomly chosen bounding boxes to occlude the background object between 20% and 80%\n",
    "This can be improved if we know the foreground image has to be some base scale to allow for above threshold occlusion\n",
    "'''\n",
    "def get_bbox_list(bg_bbox, bg_w, bg_h, fg_w, fg_h):\n",
    "\n",
    "    random.seed(time.time())\n",
    "\n",
    "    bboxes = []\n",
    "    num_boxes = 20\n",
    "    \n",
    "    for _ in range(num_boxes):\n",
    "\n",
    "        occluder_bb = get_random_bbox(bg_bbox, bg_w, bg_h, fg_w, fg_h)\n",
    "     \n",
    "        if not occluder_bb:\n",
    "            return bboxes\n",
    "        occluded_ratio = overlap_ratio(occluder_bb, bg_bbox)\n",
    "        \n",
    "        if .20 <= occluded_ratio <= .80:\n",
    "            bboxes.append((occluded_ratio, occluder_bb))\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694caa1e-c8f5-4153-ba52-92ab5bce3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gets one random bounding box. If no feasible box is found after 20 tries, None is returned\n",
    "'''\n",
    "def get_random_bbox(bg_bbox, bg_w, bg_h, fg_w, fg_h):\n",
    "    \n",
    "    occludee_x1 = bg_bbox[0]\n",
    "    occludee_y1 = bg_bbox[1] \n",
    "    occludee_x2 = bg_bbox[2]\n",
    "    occludee_y2 = bg_bbox[3]\n",
    "\n",
    "    for _ in range(20):\n",
    "        \n",
    "        random.seed(time.time())\n",
    "        \n",
    "        occluder_x1 = random.randint(max(0, occludee_x1 - fg_w), occludee_x2) # overlapping in the x-direction\n",
    "        occluder_y1 = random.randint(max(0, occludee_y1 - fg_h), occludee_y2) # overlapping in the y-direction\n",
    "\n",
    "        # TODO: Fix so doesnt exceed background image\n",
    "        occluder_x2 = occluder_x1 + fg_w\n",
    "        occluder_y2 = occluder_y1 + fg_h\n",
    "        \n",
    "        # maybe we should introduce image cropping/clipping here instead\n",
    "        if occluder_x2 <= bg_w and occluder_y2 <= bg_h:\n",
    "            return [occluder_x1, occluder_y1, occluder_x2, occluder_y2]\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf5e68-e42e-4870-a0be-0c128e349b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "import csv\n",
    "\n",
    "'''\n",
    "Get a random bounding box location for a given occlusion range. Returns None if nothing can be found.\n",
    "'''\n",
    "def get_random_location(fg_img, fg_mask, bg_img, bg_w, bg_h, bg_bbox, occ_range):\n",
    "    \n",
    "    cache_dir = './unrealistic_cache'\n",
    "    scaled_fg_dir, scaled_mask_dir, csv_path = prepare_multi_fg_scales(cache_dir, fg_img, fg_mask, bg_img, 16)\n",
    "    \n",
    "    with open(csv_path, mode='r', newline='') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            fg_name   = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            mask_name = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            fg_w = int(row['newWidth'])\n",
    "            fg_h = int(row['newHeight'])\n",
    "            \n",
    "            fg_img_path = os.path.join(scaled_fg_dir, fg_name)\n",
    "            fg_mask_path = os.path.join(scaled_mask_dir, mask_name)\n",
    "\n",
    "            occ_min, occ_max = occ_range\n",
    "            \n",
    "            # try to get a bounding box that matches the realistic occlusion level\n",
    "            for _ in range(20):\n",
    "                occluder_bb = get_random_bbox(bg_bbox, bg_w, bg_h, fg_w, fg_h)\n",
    "                if not occluder_bb:\n",
    "                    continue\n",
    "                # we need to try a different occluder size\n",
    "                occluded_ratio = overlap_ratio(occluder_bb, bg_bbox) \n",
    "                if occ_min <= occluded_ratio <= occ_max:\n",
    "                    return fg_img_path, fg_mask_path, occluded_ratio, occluder_bb\n",
    "    \n",
    "    return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bce983-70a5-4382-b39f-f3c477f6ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "returns the score, composite image, and compositive mask. \n",
    "num scales is the number of different foreground scales to try.\n",
    "'''\n",
    "from libcom import OPAScoreModel\n",
    "import csv\n",
    "from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "\n",
    "def get_optimal_location(fg_img, fg_mask, bg_img, bg_w, bg_h, bg_bbox, num_scales):\n",
    "\n",
    "    net = OPAScoreModel(device=0, model_type='SimOPA')\n",
    "    cache_dir = './realistic_cache'\n",
    "\n",
    "    scaled_fg_dir, scaled_mask_dir, csv_path = prepare_multi_fg_scales(cache_dir, fg_img, fg_mask, bg_img, 16)\n",
    "\n",
    "    score = 0\n",
    "    ratio = 0\n",
    "    optimal_bbox = None\n",
    "    best_fg = None\n",
    "    best_mask = None\n",
    "    best_comp = None \n",
    "    best_comp_mask = None\n",
    "    \n",
    "    with open(csv_path, mode='r', newline='') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            fg_name   = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            mask_name = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            fg_w = int(row['newWidth'])\n",
    "            fg_h = int(row['newHeight'])\n",
    "\n",
    "            # bg_img    = read_image_pil(bg_img)\n",
    "            bbox_list = get_bbox_list(bg_bbox, bg_w, bg_h, fg_w, fg_h)\n",
    "\n",
    "            fg_img = os.path.join(scaled_fg_dir, fg_name)\n",
    "            fg_mask = os.path.join(scaled_mask_dir, mask_name)\n",
    "\n",
    "            for occ_ratio, bbox in bbox_list:\n",
    "                comp, comp_mask = get_composite_image(fg_img, fg_mask, bg_img, bbox)\n",
    "                bbox_score = net(comp, comp_mask)\n",
    "                if bbox_score > score:\n",
    "                    best_fg = fg_img\n",
    "                    best_mask = fg_mask\n",
    "                    optimal_bbox = bbox\n",
    "                    best_comp = comp\n",
    "                    best_comp_mask = comp_mask\n",
    "                    score = bbox_score\n",
    "                    ratio = occ_ratio\n",
    "\n",
    "        return score, ratio, best_fg, best_mask, optimal_bbox, best_comp, best_comp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268561c1-e56f-4a6e-96ec-a111b075838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "'''\n",
    "Get a occluder and correspondiong mask for a given occluder size.\n",
    "If no index is provided, a random occluder is chosen\n",
    "'''\n",
    "def get_occluder():\n",
    "    random.seed(time.time())\n",
    "    \n",
    "    # get the correct path to the occluder\n",
    "    occluder_img_dir = './occluders'\n",
    "    occluder_mask_dir = './masks'\n",
    "    # load the occluders\n",
    "    # data = np.load(occluder_path, allow_pickle=True)\n",
    "    \n",
    "    files = [f for f in os.listdir(occluder_img_dir)]\n",
    "    filename = random.choice(files)\n",
    "    occ_img_path = os.path.join(occluder_img_dir, filename)\n",
    "    img_id = filename.split('.')[0]\n",
    "    \n",
    "    occ_mask_path = os.path.join(occluder_mask_dir, img_id + '.png')\n",
    "    \n",
    "    return occ_img_path, occ_mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4dbd1e-5ee3-4957-9ca4-2c30e0a0b18e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_specific_occluder(bg_img_path):\n",
    "    \n",
    "    img_id = bg_img_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    fg_img_path = f'./FG/{img_id}_mask.png'\n",
    "    fg_mask_path = f'./FG/{img_id}.jpg'\n",
    "    return fg_img_path, fg_mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55accc2a-f490-4107-82b7-da95b910d323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "'''\n",
    "Write output to an annotation file\n",
    "'''\n",
    "def write_one_annotation(save_path, bg_img, cate, occlusion_level, occlusion_ratio, occluder_path, fg_bb, bg_bb):\n",
    "    annotation = {}\n",
    "    annotation['box'] = bg_bb.tolist() \n",
    "    annotation['ratio'] = occlusion_ratio\n",
    "    annotation['occluder_box'] = fg_bb\n",
    "    annotation['occluder_path'] = occluder_path\n",
    "    annotation['source'] = bg_img\n",
    "    annotation['cate'] = cate\n",
    "    \n",
    "    img_id = bg_img.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    # Convert and write JSON object to file\n",
    "    with open(f'{save_path}/annotations/{occlusion_level}/{img_id}.json', \"w\") as outfile: \n",
    "        json.dump(annotation, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138f32b-47d2-44d2-9dff-51d5deb6463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libcom import color_transfer\n",
    "from libcom.utils.process_image import *\n",
    "from libcom.utils.environment import *\n",
    "from libcom import OPAScoreModel\n",
    "from libcom import get_composite_image\n",
    "from libcom.utils.process_image import make_image_grid\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image\n",
    "from libcom import Mure_ObjectStitchModel\n",
    "import json\n",
    "\n",
    "def generate_images(cate, bg_img_path, bg_w, bg_h, bg_bbox, save_real, save_unreal, record_file):\n",
    "\n",
    "    net = Mure_ObjectStitchModel(device=0, sampler='plms')\n",
    "    annotation = {}\n",
    "    print(bg_img_path)\n",
    "        \n",
    "    real_fg_img_path, real_fg_mask_path =  get_specific_occluder(bg_img_path)\n",
    "    img_id = bg_img_path.split('/')[-1].split('.')[0]\n",
    "     \n",
    "    score, real_ratio, op_fg_img_path, op_fg_mask_path, op_bbox, _, _ = get_optimal_location(real_fg_img_path, real_fg_mask_path, bg_img_path, bg_w, bg_h, bg_bbox, num_scales=16)\n",
    "    \n",
    "    if not score:\n",
    "        record_file.write(f'Skipped {bg_img_path}. Couldnt find optimal location.')\n",
    "            # we couldnt find a possible foreground location, so we just skip everything\n",
    "        return\n",
    "\n",
    "        # write to a directory based on the level of occlusion\n",
    "    occlusion_level = None\n",
    "    for range_label, (min_occ, max_occ) in occlusion_ranges.items():\n",
    "        if min_occ <= real_ratio <= max_occ:\n",
    "            occlusion_level = range_label\n",
    "\n",
    "    # first, we get a random occluder\n",
    "    # unreal_fg_img_path, unreal_fg_mask_path = get_occluder()\n",
    "\n",
    "    # get a bounding box and ratio for an occlusion that falls into the bin\n",
    "    #random_fg_img_path, random_fg_mask_path, unreal_ratio, random_bbox = get_random_location(unreal_fg_img_path, unreal_fg_mask_path, bg_img_path, bg_w, bg_h, bg_bbox, occlusion_ranges[occlusion_level])\n",
    "        \n",
    "    # if not random_fg_img_path:\n",
    "    #     record_file.write(f'Skipped {bg_img_path}. Couldnt find random location/')\n",
    "    #     # we couldnt find a reasonable foreground, so we skip writing out anything for both foreground and background\n",
    "    #     return\n",
    "            \n",
    "    # realistic image\n",
    "    write_one_annotation(save_real, bg_img_path, cate, occlusion_level, real_ratio, real_fg_img_path, op_bbox, bg_bbox)\n",
    "    res, _ = net(bg_img_path, [op_fg_img_path], [op_fg_mask_path], op_bbox, sample_steps=25, num_samples=3)\n",
    "    # TODO: find the best result in res, instead of just taking the last sample\n",
    "    cv2.imwrite(f'{save_real}/images/{occlusion_level}/{img_id}.jpg', res[2])\n",
    "        \n",
    "    # unrealistic image\n",
    "    # write_one_annotation(save_unreal, bg_img_path, cate, occlusion_level, unreal_ratio, unreal_fg_img_path, random_bbox, bg_bbox)\n",
    "    # comp, _ = get_composite_image(random_fg_img_path, random_fg_mask_path, bg_img_path, random_bbox)\n",
    "    # cv2.imwrite(f'{save_unreal}/images/{occlusion_level}/{img_id}.jpg', comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655fa44-9c2d-4f2e-8475-f603bfd6e925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import BboxTools as bbt\n",
    "import os\n",
    "\n",
    "# the only reason we have bg_mask_dir is in case we need it for segmentation masks...\n",
    "def generate_dataset(cate, file_list, bg_img_dir, bg_anno_dir, save_real, save_unreal, tem):\n",
    "    \n",
    "    for file_name in file_list[5:25]:\n",
    "        bg_w, bg_h, bg_bbox, flag_ = load_one_annotation(os.path.join(bg_anno_dir, file_name + '.mat'))\n",
    "\n",
    "        if flag_:\n",
    "            record_file.write('Skipped %s for multi objects\\n' % file_name)\n",
    "            continue\n",
    "        \n",
    "        bg_img_path = os.path.join(bg_img_dir, file_name + '.JPEG')\n",
    "        \n",
    "        generate_images(cate, bg_img_path, bg_w, bg_h, bg_bbox, save_real, save_unreal, tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ce0f1-a105-4249-9d14-93352872913d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = ['bus', 'car', 'motorbike']\n",
    "\n",
    "real_save = './realistic'\n",
    "unreal_save = './unrealistic'\n",
    "\n",
    "path_to_original_pascal3dp = '/srv/PASCAL3D+_release1.1/'\n",
    "bg_list_path = path_to_original_pascal3dp + 'Image_sets/%s_imagenet_val.txt'\n",
    "bg_img_path = path_to_original_pascal3dp + 'Images/%s_imagenet'\n",
    "bg_anno_path = path_to_original_pascal3dp + 'Annotations/%s_imagenet'\n",
    "bg_mask_path = path_to_original_pascal3dp + 'obj_mask/%s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52523ee-ca63-46ad-9c0c-5ae2ec6fe981",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [real_save, unreal_save]:\n",
    "    for data_type in ['images', 'annotations']:\n",
    "        for range_label in occlusion_ranges.keys():\n",
    "            os.makedirs(dataset + \"/\" + data_type + \"/\" + range_label, exist_ok=True)\n",
    "\n",
    "for cate in categories:\n",
    "    print('Start cate: ', cate)\n",
    "    tem = open('generating_record_%s_1030.txt' % cate, 'w')\n",
    "    file_list_ = open(bg_list_path % cate).readlines()\n",
    "    file_list_ = [tem.strip('\\n') for tem in file_list_]\n",
    "    bg_img_path_ = bg_img_path % cate\n",
    "    bg_anno_path_ = bg_anno_path % cate\n",
    "\n",
    "    generate_dataset(cate, file_list_, bg_img_path_, bg_anno_path_, real_save, unreal_save, tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272e552-56ff-42f5-94d3-de2183897032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libcom import Mure_ObjectStitchModel\n",
    "bg_img_path = 'BG/n02924116_11237.JPEG'\n",
    "net = Mure_ObjectStitchModel(device=0, sampler='plms')\n",
    "\n",
    "res, _ = net(bg_img_path, \n",
    "             ['random_occluders/fg_img_1040.jpg'], \n",
    "             ['random_occluders/fg_mask_1040.png'], \n",
    "             [116, 127, 421, 344], \n",
    "             sample_steps=25, \n",
    "             num_samples=3) \n",
    "\n",
    "cv2.imwrite(f'./gest.jpg', res[0])\n",
    "cv2.imwrite(f'./gest1.jpg', res[1])\n",
    "cv2.imwrite(f'./gest2.jpg', res[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08579371-43c5-4b86-9fcc-6448bbb3d229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='BG/n02924116_11237.JPEG') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9e3cc-cb24-4140-bdfa-f1617bc5bce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from libcom import Mure_ObjectStitchModel\n",
    "from libcom.utils.process_image import make_image_grid, draw_bbox_on_image\n",
    "import cv2\n",
    "import os\n",
    "net    = Mure_ObjectStitchModel(device=0, sampler='plms')\n",
    "sample_list = ['000000000003', '000000000004']\n",
    "sample_dir  = '../workspace/libcom/tests/mure_objectstitch/'\n",
    "bbox_list   = [[623, 1297, 1159, 1564], [363, 205, 476, 276]]\n",
    "for i, sample in enumerate(sample_list):\n",
    "    bg_img = sample_dir + f'background/{sample}.jpg'\n",
    "    fg_img_path = sample_dir + f'foreground/{sample}/'\n",
    "    fg_mask_path = sample_dir + f'foreground_mask/{sample}/'\n",
    "\n",
    "    fg_img_list = [os.path.join(fg_img_path, f) for f in os.listdir(fg_img_path)]\n",
    "    fg_mask_list = [os.path.join(fg_mask_path, f) for f in os.listdir(fg_mask_path)]\n",
    "    bbox   = bbox_list[i]\n",
    "    comp, show_fg_img = net(bg_img, fg_img_list, fg_mask_list, bbox, sample_steps=25, num_samples=3)\n",
    "    # bg_img   = draw_bbox_on_image(bg_img, bbox)\n",
    "    # grid_img = make_image_grid([bg_img, show_fg_img] + [comp[i] for i in range(len(comp))])\n",
    "    cv2.imwrite(f'../workspace/libcom/docs/_static/image/mureobjectstitch_result{i+1}.jpg', comp[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibCom Environment (Local)",
   "language": "python",
   "name": "libcom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
