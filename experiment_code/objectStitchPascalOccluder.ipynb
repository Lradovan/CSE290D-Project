{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f821bb-27fa-4292-9d86-181f90d27a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "occlusion_ranges = {\n",
    "    \"low\": (0.2, 0.4),\n",
    "    \"medium\": (0.4, 0.6),\n",
    "    \"high\": (0.6, 0.8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00d29f1-e78a-4b3e-bf65-5f2da434fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def load_one_annotation(anno_path):\n",
    "    a = scipy.io.loadmat(anno_path)\n",
    "    # I added the astype int here....\n",
    "    bbox_ = a['record'][0][0][1][0][0][1][0].astype(int)\n",
    "    w = a['record']['size'][0][0][0][0][0][0][0]\n",
    "    h = a['record']['size'][0][0][0][0][1][0][0]\n",
    "    num_obj = len(a['record'][0][0][1][0])\n",
    "    return w, h, bbox_, num_obj != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c62389-e92d-470f-b1a3-86e1b646d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get overlap percentage based on bounding boxes\n",
    "'''\n",
    "def overlap_ratio(occluder_bb, occludee_bb):\n",
    "\n",
    "    #top left and bottom right points\n",
    "    occluder_x1, occluder_y1, occluder_x2, occluder_y2 = occluder_bb\n",
    "    occludee_x1, occludee_y1, occludee_x2, occludee_y2 = occludee_bb\n",
    "\n",
    "    # area of the foreground object\n",
    "    occludee_area = (occludee_x2 - occludee_x1) * (occludee_y2 - occludee_y1)\n",
    "\n",
    "    # area of the background object being covered by the foreground object\n",
    "    overlap_area = max(0, min(occludee_x2, occluder_x2) - max(occludee_x1, occluder_x1)) * max(0, min(occludee_y2, occluder_y2) - max(occludee_y1, occluder_y1))\n",
    "\n",
    "    # overlap over the total background object area\n",
    "    return overlap_area / occludee_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96a0873-b634-49dd-a8e1-1965c12dfb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "'''\n",
    "Get a list of randomly chosen bounding boxes to occlude the background object between 20% and 80%\n",
    "This can be improved if we know the foreground image has to be some base scale to allow for above threshold occlusion\n",
    "'''\n",
    "def get_bbox_list(bg_bbox, bg_w, bg_h, fg_w, fg_h):\n",
    "\n",
    "    random.seed(time.time())\n",
    "\n",
    "    bboxes = []\n",
    "    num_boxes = 20\n",
    "    \n",
    "    for _ in range(num_boxes):\n",
    "\n",
    "        occluder_bb = get_random_bbox(bg_bbox, bg_w, bg_h, fg_w, fg_h)\n",
    "     \n",
    "        if not occluder_bb:\n",
    "            return bboxes\n",
    "        occluded_ratio = overlap_ratio(occluder_bb, bg_bbox)\n",
    "        \n",
    "        if .20 <= occluded_ratio <= .80:\n",
    "            bboxes.append((occluded_ratio, occluder_bb))\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694caa1e-c8f5-4153-ba52-92ab5bce3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gets one random bounding box. If no feasible box is found after 20 tries, None is returned\n",
    "'''\n",
    "\n",
    "def get_random_bbox(bg_bbox, bg_w, bg_h, fg_w, fg_h):\n",
    "    \n",
    "    occludee_x1 = bg_bbox[0]\n",
    "    occludee_y1 = bg_bbox[1] \n",
    "    occludee_x2 = bg_bbox[2]\n",
    "    occludee_y2 = bg_bbox[3]\n",
    "\n",
    "    for _ in range(20):\n",
    "        \n",
    "        random.seed(time.time())\n",
    "        \n",
    "        occluder_x1 = random.randint(max(0, occludee_x1 - fg_w), occludee_x2) # overlapping in the x-direction\n",
    "        occluder_y1 = random.randint(max(0, occludee_y1 - fg_h), occludee_y2) # overlapping in the y-direction\n",
    "\n",
    "        # TODO: Fix so doesnt exceed background image\n",
    "        occluder_x2 = occluder_x1 + fg_w\n",
    "        occluder_y2 = occluder_y1 + fg_h\n",
    "        \n",
    "        # maybe we should introduce image cropping/clipping here instead\n",
    "        if occluder_x2 <= bg_w and occluder_y2 <= bg_h:\n",
    "            return [occluder_x1, occluder_y1, occluder_x2, occluder_y2]\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61bf5e68-e42e-4870-a0be-0c128e349b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module 'xformers'. Proceeding without it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Libcom/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:258: LightningDeprecationWarning: `pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will be removed in v2.0.0. You can import it from `pytorch_lightning.utilities` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "import csv\n",
    "\n",
    "'''\n",
    "Get a random bounding box location for a given occlusion range. Returns None if nothing can be found.\n",
    "'''\n",
    "def get_random_location(fg_img, fg_mask, bg_img, bg_w, bg_h, bg_bbox, occ_range):\n",
    "    \n",
    "    cache_dir = './unrealistic_cache'\n",
    "    scaled_fg_dir, scaled_mask_dir, csv_path = prepare_multi_fg_scales(cache_dir, fg_img, fg_mask, bg_img, 16)\n",
    "    \n",
    "    with open(csv_path, mode='r', newline='') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            fg_name   = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            mask_name = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            fg_w = int(row['newWidth'])\n",
    "            fg_h = int(row['newHeight'])\n",
    "            \n",
    "            fg_img_path = os.path.join(scaled_fg_dir, fg_name)\n",
    "            fg_mask_path = os.path.join(scaled_mask_dir, mask_name)\n",
    "\n",
    "            occ_min, occ_max = occ_range\n",
    "            \n",
    "            # try to get a bounding box that matches the realistic occlusion level\n",
    "            for _ in range(20):\n",
    "                occluder_bb = get_random_bbox(bg_bbox, bg_w, bg_h, fg_w, fg_h)\n",
    "                if not occluder_bb:\n",
    "                    continue\n",
    "                # we need to try a different occluder size\n",
    "                occluded_ratio = overlap_ratio(occluder_bb, bg_bbox) \n",
    "                if occ_min <= occluded_ratio <= occ_max:\n",
    "                    return fg_img_path, fg_mask_path, occluded_ratio, occluder_bb\n",
    "    \n",
    "    return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5bce983-70a5-4382-b39f-f3c477f6ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "returns the score, composite image, and compositive mask. \n",
    "num scales is the number of different foreground scales to try.\n",
    "'''\n",
    "from libcom import OPAScoreModel\n",
    "import csv\n",
    "from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "\n",
    "def get_optimal_location(fg_img, fg_mask, bg_img, bg_w, bg_h, bg_bbox, num_scales):\n",
    "\n",
    "    net = OPAScoreModel(device=0, model_type='SimOPA')\n",
    "    cache_dir = './realistic_cache'\n",
    "\n",
    "    scaled_fg_dir, scaled_mask_dir, csv_path = prepare_multi_fg_scales(cache_dir, fg_img, fg_mask, bg_img, 16)\n",
    "\n",
    "    score = 0\n",
    "    ratio = 0\n",
    "    optimal_bbox = None\n",
    "    best_fg = None\n",
    "    best_mask = None\n",
    "    best_comp = None \n",
    "    best_comp_mask = None\n",
    "    \n",
    "    with open(csv_path, mode='r', newline='') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            fg_name   = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            mask_name = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            fg_w = int(row['newWidth'])\n",
    "            fg_h = int(row['newHeight'])\n",
    "\n",
    "            # bg_img    = read_image_pil(bg_img)\n",
    "            bbox_list = get_bbox_list(bg_bbox, bg_w, bg_h, fg_w, fg_h)\n",
    "\n",
    "            fg_img = os.path.join(scaled_fg_dir, fg_name)\n",
    "            fg_mask = os.path.join(scaled_mask_dir, mask_name)\n",
    "\n",
    "            for occ_ratio, bbox in bbox_list:\n",
    "                comp, comp_mask = get_composite_image(fg_img, fg_mask, bg_img, bbox)\n",
    "                bbox_score = net(comp, comp_mask)\n",
    "                if bbox_score > score:\n",
    "                    best_fg = fg_img\n",
    "                    best_mask = fg_mask\n",
    "                    optimal_bbox = bbox\n",
    "                    best_comp = comp\n",
    "                    best_comp_mask = comp_mask\n",
    "                    score = bbox_score\n",
    "                    ratio = occ_ratio\n",
    "\n",
    "        return score, ratio, best_fg, best_mask, optimal_bbox, best_comp, best_comp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268561c1-e56f-4a6e-96ec-a111b075838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "'''\n",
    "Get a occluder and correspondiong mask for a given occluder size.\n",
    "If no index is provided, a random occluder is chosen\n",
    "'''\n",
    "def get_occluder(occ_size, index=None):\n",
    "    random.seed(time.time())\n",
    "    \n",
    "    # get the correct path to the occluder\n",
    "    occluder_path = '/srv/occluder_libs_test_' + occ_size + '.npz'\n",
    "    \n",
    "    # load the occluders\n",
    "    data = np.load(occluder_path, allow_pickle=True)\n",
    "    \n",
    "    if not index:\n",
    "        index = random.randint(0, len(data['images'])-1)\n",
    "\n",
    "    # save the occluders\n",
    "    os.makedirs('./occluders', exist_ok=True)\n",
    "    occ_img = f'./occluders/fg_img_{index}.jpg'\n",
    "    occ_mask = f'./occluders/fg_mask_{index}.png'\n",
    "\n",
    "    image = data['images'][index]\n",
    "    box = data['boxes'][index]\n",
    "    mask = data['masks'][index]\n",
    "    \n",
    "    mask = (mask * 255)\n",
    "    \n",
    "    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "    cv2.imwrite(occ_img, image_bgr)\n",
    "    cv2.imwrite(occ_mask, mask)\n",
    "    \n",
    "    h = box[1] - box[0]\n",
    "    w = box[3] - box[2]\n",
    "\n",
    "    return occ_img, occ_mask, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55accc2a-f490-4107-82b7-da95b910d323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "'''\n",
    "Write output to an annotation file\n",
    "'''\n",
    "\n",
    "def write_one_annotation(save_path, bg_img, cate, occ_size, occlusion_level, occlusion_ratio, occluder_path, fg_bb, bg_bb):\n",
    "    annotation = {}\n",
    "    annotation['box'] = bg_bb.tolist() \n",
    "    annotation['ratio'] = occlusion_ratio\n",
    "    annotation['occluder_box'] = fg_bb\n",
    "    annotation['occluder_path'] = occluder_path\n",
    "    annotation['source'] = bg_img\n",
    "    annotation['cate'] = cate\n",
    "    \n",
    "    img_id = bg_img.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    # Convert and write JSON object to file\n",
    "    with open(f'{save_path}/annotations/{occlusion_level}/{occ_size}_{img_id}.json', \"w\") as outfile: \n",
    "        json.dump(annotation, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3138f32b-47d2-44d2-9dff-51d5deb6463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libcom import color_transfer\n",
    "from libcom.utils.process_image import *\n",
    "from libcom.utils.environment import *\n",
    "from libcom import OPAScoreModel\n",
    "from libcom import get_composite_image\n",
    "from libcom.utils.process_image import make_image_grid\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image\n",
    "from libcom import Mure_ObjectStitchModel\n",
    "import json\n",
    "\n",
    "def generate_images(cate, bg_img_path, bg_w, bg_h, bg_bbox, fg_indices, save_real, save_unreal, record_file):\n",
    "\n",
    "    net = Mure_ObjectStitchModel(device=0, sampler='plms')\n",
    "    annotation = {}\n",
    "    print(bg_img_path)\n",
    "    \n",
    "    for (occ_size, fg_index) in fg_indices:\n",
    "        \n",
    "        real_fg_img_path, real_fg_mask_path, _, _ = get_occluder(occ_size, fg_index)\n",
    "\n",
    "        img_id = bg_img_path.split('/')[-1].split('.')[0]\n",
    "     \n",
    "        score, real_ratio, op_fg_img_path, op_fg_mask_path, op_bbox, _, _ = get_optimal_location(real_fg_img_path, real_fg_mask_path, bg_img_path, bg_w, bg_h, bg_bbox, num_scales=16)\n",
    "    \n",
    "        if not score:\n",
    "            record_file.write(f'Skipped {occ_size} for {bg_img_path}. Couldnt find optimal location.')\n",
    "            # we couldnt find a possible foreground location, so we just skip everything\n",
    "            continue\n",
    "\n",
    "        # write to a directory based on the level of occlusion\n",
    "        occlusion_level = None\n",
    "        for range_label, (min_occ, max_occ) in occlusion_ranges.items():\n",
    "            if min_occ <= real_ratio <= max_occ:\n",
    "                occlusion_level = range_label\n",
    "\n",
    "        # first, we get a random occluder\n",
    "        unreal_fg_img_path, unreal_fg_mask_path, fg_w, fg_h = get_occluder(occ_size)\n",
    "\n",
    "        # get a bounding box and ratio for an occlusion that falls into the bin\n",
    "        random_fg_img_path, random_fg_mask_path, unreal_ratio, random_bbox = get_random_location(unreal_fg_img_path, unreal_fg_mask_path, bg_img_path, bg_w, bg_h, bg_bbox, occlusion_ranges[occlusion_level])\n",
    "        \n",
    "        if not random_fg_img_path:\n",
    "            record_file.write(f'Skipped {occ_size} for {bg_img_path}. Couldnt find random location/')\n",
    "             # we couldnt find a reasonable foreground, so we skip writing out anything for both foreground and background\n",
    "            continue\n",
    "            \n",
    "        # realistic image\n",
    "        write_one_annotation(save_real, bg_img_path, cate, occ_size, occlusion_level, real_ratio, real_fg_img_path, op_bbox, bg_bbox)\n",
    "        res, _ = net(bg_img_path, [op_fg_img_path], [op_fg_mask_path], op_bbox, sample_steps=25, num_samples=3)\n",
    "        # TODO: find the best result in res, instead of just taking the last sample\n",
    "        cv2.imwrite(f'{save_real}/images/{occlusion_level}/{occ_size}_{img_id}.jpg', res[2])\n",
    "        \n",
    "        # unrealistic image\n",
    "        write_one_annotation(save_unreal, bg_img_path, cate, occ_size, occlusion_level, unreal_ratio, unreal_fg_img_path, random_bbox, bg_bbox)\n",
    "        comp, _ = get_composite_image(random_fg_img_path, random_fg_mask_path, bg_img_path, random_bbox)\n",
    "        cv2.imwrite(f'{save_unreal}/images/{occlusion_level}/{occ_size}_{img_id}.jpg', comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b3f68b-b0c2-4b59-997f-23db0dd50952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "path_to_original_pascal3dp = '/srv/PASCAL3D+_release1.1/'\n",
    "bg_anno_dir = path_to_original_pascal3dp + 'Annotations/'\n",
    "csv_path = './bg_fg_pair.csv'\n",
    "real_save = './realistic'\n",
    "unreal_save = './unrealistic'\n",
    "record_file = open('generating_record_.txt', 'w')\n",
    "\n",
    "'''\n",
    "Set up the necessary directories\n",
    "'''\n",
    "\n",
    "for dataset in [real_save, unreal_save]:\n",
    "    for data_type in ['images', 'annotations']:\n",
    "        for range_label in occlusion_ranges.keys():\n",
    "            os.makedirs(dataset + \"/\" + data_type + \"/\" + range_label, exist_ok=True)\n",
    "\n",
    "with open(csv_path, mode='r', newline='') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for i, row in enumerate(csv_reader):\n",
    "        \n",
    "        if i < 100: continue\n",
    "        if i > 110:break\n",
    "        \n",
    "        bg_img_path = row['image_name']\n",
    "        fg_index_small = int(row['fg_index_small'])\n",
    "        fg_index_medium = int(row['fg_index_medium'])\n",
    "        fg_index_large = int(row['fg_index_large'])\n",
    "        \n",
    "        fg_indices = ((\"small\", fg_index_small), (\"medium\", fg_index_medium), (\"large\", fg_index_large))\n",
    "        \n",
    "        category = bg_img_path.split('/')[4].split('_')[0]\n",
    "        img_id = bg_img_path.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        bg_anno_path = os.path.join(bg_anno_dir, category + '_imagenet', img_id + '.mat')\n",
    "        \n",
    "        # load the annotation file for the background img\n",
    "        bg_w, bg_h, bg_bbox, flag_ = load_one_annotation(bg_anno_path)\n",
    "        \n",
    "        if flag_:\n",
    "            record_file.write('Skipped %s for multi objects\\n' % file_name)\n",
    "            continue\n",
    "        \n",
    "        generate_images(category, bg_img_path, bg_w, bg_h, bg_bbox, fg_indices, real_save, unreal_save, record_file)\n",
    "        \n",
    "record_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibCom Environment (Local)",
   "language": "python",
   "name": "libcom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
