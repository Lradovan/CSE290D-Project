{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f821bb-27fa-4292-9d86-181f90d27a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "occlusion_ranges = {\n",
    "    \"low\": (0.2, 0.4),\n",
    "    \"medium\": (0.4, 0.6),\n",
    "    \"high\": (0.6, 0.8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00d29f1-e78a-4b3e-bf65-5f2da434fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def load_one_annotation(anno_path):\n",
    "    a = scipy.io.loadmat(anno_path)\n",
    "    # I added the astype int here....\n",
    "    bbox_ = a['record'][0][0][1][0][0][1][0].astype(int)\n",
    "    w = a['record']['size'][0][0][0][0][0][0][0]\n",
    "    h = a['record']['size'][0][0][0][0][1][0][0]\n",
    "    num_obj = len(a['record'][0][0][1][0])\n",
    "    return w, h, bbox_, num_obj != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c62389-e92d-470f-b1a3-86e1b646d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "get overlap percentage based on bounding boxes\n",
    "'''\n",
    "def overlap_ratio(occluder_bb, occludee_bb):\n",
    "\n",
    "    #top left and bottom right points\n",
    "    occluder_x1, occluder_y1, occluder_x2, occluder_y2 = occluder_bb\n",
    "    occludee_x1, occludee_y1, occludee_x2, occludee_y2 = occludee_bb\n",
    "\n",
    "    # area of the foreground object\n",
    "    occludee_area = (occludee_x2 - occludee_x1) * (occludee_y2 - occludee_y1)\n",
    "\n",
    "    # area of the background object being covered by the foreground object\n",
    "    overlap_area = max(0, min(occludee_x2, occluder_x2) - max(occludee_x1, occluder_x1)) * max(0, min(occludee_y2, occluder_y2) - max(occludee_y1, occluder_y1))\n",
    "\n",
    "    # overlap over the total background object area\n",
    "    return overlap_area / occludee_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96a0873-b634-49dd-a8e1-1965c12dfb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "'''\n",
    "Get a list of randomly chosen bounding boxes to occlude the background object between 20% and 80%\n",
    "This can be improved if we know the foreground image has to be some base scale to allow for above threshold occlusion\n",
    "'''\n",
    "def get_bbox_list(bg_bbox, bg_w, bg_h, fg_w, fg_h):\n",
    "\n",
    "    random.seed(time.time())\n",
    "\n",
    "    bboxes = []\n",
    "    num_boxes = 20\n",
    "    \n",
    "    for _ in range(num_boxes):\n",
    "\n",
    "        occluder_bb = get_random_bbox(bg_bbox, bg_w, bg_h, fg_w, fg_h)\n",
    "     \n",
    "        if not occluder_bb:\n",
    "            return bboxes\n",
    "        occluded_ratio = overlap_ratio(occluder_bb, bg_bbox)\n",
    "        \n",
    "        if .20 <= occluded_ratio <= .80:\n",
    "            bboxes.append((occluded_ratio, occluder_bb))\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694caa1e-c8f5-4153-ba52-92ab5bce3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gets one random bounding box. If no feasible box is found after 20 tries, None is returned\n",
    "'''\n",
    "def get_random_bbox(bg_bbox, bg_w, bg_h, fg_w, fg_h):\n",
    "    \n",
    "    occludee_x1 = bg_bbox[0]\n",
    "    occludee_y1 = bg_bbox[1] \n",
    "    occludee_x2 = bg_bbox[2]\n",
    "    occludee_y2 = bg_bbox[3]\n",
    "\n",
    "    for _ in range(20):\n",
    "        \n",
    "        random.seed(time.time())\n",
    "        \n",
    "        occluder_x1 = random.randint(max(0, occludee_x1 - fg_w), occludee_x2) # overlapping in the x-direction\n",
    "        occluder_y1 = random.randint(max(0, occludee_y1 - fg_h), occludee_y2) # overlapping in the y-direction\n",
    "\n",
    "        # TODO: Fix so doesnt exceed background image\n",
    "        occluder_x2 = occluder_x1 + fg_w\n",
    "        occluder_y2 = occluder_y1 + fg_h\n",
    "        \n",
    "        # maybe we should introduce image cropping/clipping here instead\n",
    "        if occluder_x2 <= bg_w and occluder_y2 <= bg_h:\n",
    "            return [occluder_x1, occluder_y1, occluder_x2, occluder_y2]\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc099d0-0942-420b-88aa-a0429b6642f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generate a mask using a bounding box and a background image.\n",
    "'''\n",
    "def bounding_box_to_mask(bg_img_path, bbox):\n",
    "    background = cv2.imread(bg_img_path)\n",
    "    height, width = background.shape[:2]\n",
    "    \n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    x1, y1, x2, y2 = bbox\n",
    "    cv2.rectangle(mask, (x1, y1), (x2, y2), color=255, thickness=-1)  # -1 to fill the rectangle\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61bf5e68-e42e-4870-a0be-0c128e349b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module 'xformers'. Proceeding without it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Libcom/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:258: LightningDeprecationWarning: `pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will be removed in v2.0.0. You can import it from `pytorch_lightning.utilities` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "import csv\n",
    "\n",
    "'''\n",
    "Get a random bounding box location for a given occlusion range. Returns None if nothing can be found.\n",
    "'''\n",
    "def get_random_location(fg_img, fg_mask, bg_img, bg_w, bg_h, bg_bbox, occ_range):\n",
    "    \n",
    "    cache_dir = './unrealistic_cache'\n",
    "    scaled_fg_dir, scaled_mask_dir, csv_path = prepare_multi_fg_scales(cache_dir, fg_img, fg_mask, bg_img, 16)\n",
    "    \n",
    "    with open(csv_path, mode='r', newline='') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            fg_name   = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            mask_name = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            fg_w = int(row['newWidth'])\n",
    "            fg_h = int(row['newHeight'])\n",
    "            \n",
    "            fg_img_path = os.path.join(scaled_fg_dir, fg_name)\n",
    "            fg_mask_path = os.path.join(scaled_mask_dir, mask_name)\n",
    "\n",
    "            occ_min, occ_max = occ_range\n",
    "            \n",
    "            # try to get a bounding box that matches the realistic occlusion level\n",
    "            for _ in range(20):\n",
    "                occluder_bb = get_random_bbox(bg_bbox, bg_w, bg_h, fg_w, fg_h)\n",
    "                if not occluder_bb:\n",
    "                    continue\n",
    "                # we need to try a different occluder size\n",
    "                occluded_ratio = overlap_ratio(occluder_bb, bg_bbox) \n",
    "                if occ_min <= occluded_ratio <= occ_max:\n",
    "                    return fg_img_path, fg_mask_path, occluded_ratio, occluder_bb\n",
    "    \n",
    "    return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5bce983-70a5-4382-b39f-f3c477f6ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "returns the score, composite image, and compositive mask. \n",
    "num scales is the number of different foreground scales to try.\n",
    "'''\n",
    "from libcom import OPAScoreModel\n",
    "import csv\n",
    "from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "\n",
    "def get_optimal_location(fg_img, fg_mask, bg_img, bg_w, bg_h, bg_bbox, num_scales):\n",
    "\n",
    "    net = OPAScoreModel(device=0, model_type='SimOPA')\n",
    "    cache_dir = './realistic_cache'\n",
    "\n",
    "    scaled_fg_dir, scaled_mask_dir, csv_path = prepare_multi_fg_scales(cache_dir, fg_img, fg_mask, bg_img, 16)\n",
    "\n",
    "    score = 0\n",
    "    ratio = 0\n",
    "    optimal_bbox = None\n",
    "    best_fg = None\n",
    "    best_mask = None\n",
    "    best_comp = None \n",
    "    best_comp_mask = None\n",
    "    \n",
    "    with open(csv_path, mode='r', newline='') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            fg_name   = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            mask_name = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            fg_w = int(row['newWidth'])\n",
    "            fg_h = int(row['newHeight'])\n",
    "\n",
    "            # bg_img    = read_image_pil(bg_img)\n",
    "            bbox_list = get_bbox_list(bg_bbox, bg_w, bg_h, fg_w, fg_h)\n",
    "\n",
    "            fg_img = os.path.join(scaled_fg_dir, fg_name)\n",
    "            fg_mask = os.path.join(scaled_mask_dir, mask_name)\n",
    "\n",
    "            for occ_ratio, bbox in bbox_list:\n",
    "                comp, comp_mask = get_composite_image(fg_img, fg_mask, bg_img, bbox)\n",
    "                bbox_score = net(comp, comp_mask)\n",
    "                if bbox_score > score:\n",
    "                    best_fg = fg_img\n",
    "                    best_mask = fg_mask\n",
    "                    optimal_bbox = bbox\n",
    "                    best_comp = comp\n",
    "                    best_comp_mask = comp_mask\n",
    "                    score = bbox_score\n",
    "                    ratio = occ_ratio\n",
    "\n",
    "        return score, ratio, best_fg, best_mask, optimal_bbox, best_comp, best_comp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "268561c1-e56f-4a6e-96ec-a111b075838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "'''\n",
    "Get a occluder and correspondiong mask for a given occluder size.\n",
    "If no index is provided, a random occluder is chosen\n",
    "'''\n",
    "def get_realistic_occluder(category):\n",
    "    # random.seed(time.time())\n",
    "    \n",
    "    # get the correct path to the occluder\n",
    "    occluder_img_dir = './occluders'\n",
    "    occluder_mask_dir = './masks'\n",
    "    # load the occluders\n",
    "    # data = np.load(occluder_path, allow_pickle=True)\n",
    "    files = [f for f in os.listdir(occluder_img_dir) if os.path.isfile(os.path.join(occluder_img_dir, f))]\n",
    "    \n",
    "    # make sure we don't pick an occluder from the same category as the background image\n",
    "    filename = None\n",
    "    while True:\n",
    "        filename = random.choice(files)\n",
    "        if filename.split('_')[0] != category:\n",
    "            break\n",
    "            \n",
    "    occ_img_path = os.path.join(occluder_img_dir, filename)\n",
    "    img_id = filename.split('.')[0]\n",
    "    \n",
    "    occ_mask_path = os.path.join(occluder_mask_dir, img_id + '.png')\n",
    "    \n",
    "    return occ_img_path, occ_mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af2079a-9c71-4034-aa93-6feeb82efb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "'''\n",
    "Get a occluder and correspondiong mask for a given occluder size.\n",
    "If no index is provided, a random occluder is chosen\n",
    "'''\n",
    "def get_unrealistic_occluder():\n",
    "    random.seed(time.time())\n",
    "    \n",
    "    # get the correct path to the occluder\n",
    "    occluder_path = '/srv/occluder_libs_test_medium.npz'\n",
    "    \n",
    "    # load the occluders\n",
    "    data = np.load(occluder_path, allow_pickle=True)\n",
    "    \n",
    "    index = random.randint(0, len(data['images'])-1)\n",
    "\n",
    "    # save the occluders\n",
    "    os.makedirs('./random_occluders', exist_ok=True)\n",
    "    occ_img = f'./random_occluders/fg_img_{index}.jpg'\n",
    "    occ_mask = f'./random_occluders/fg_mask_{index}.png'\n",
    "    \n",
    "    image = data['images'][index]\n",
    "    box = data['boxes'][index]\n",
    "    mask = data['masks'][index]\n",
    "    \n",
    "    mask = (mask * 255)\n",
    "    \n",
    "    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "    cv2.imwrite(occ_img, image_bgr)\n",
    "    cv2.imwrite(occ_mask, mask)\n",
    "    \n",
    "    h = box[1] - box[0]\n",
    "    w = box[3] - box[2]\n",
    "\n",
    "    return occ_img, occ_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55accc2a-f490-4107-82b7-da95b910d323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "'''\n",
    "Write output to an annotation file\n",
    "'''\n",
    "def write_one_annotation(save_path, bg_img, cate, occlusion_level, occlusion_ratio, occluder_path, fg_bb, bg_bb):\n",
    "    annotation = {}\n",
    "    annotation['box'] = bg_bb.tolist() \n",
    "    annotation['ratio'] = occlusion_ratio\n",
    "    annotation['occluder_box'] = fg_bb\n",
    "    annotation['occluder_path'] = occluder_path\n",
    "    annotation['source'] = bg_img\n",
    "    annotation['cate'] = cate\n",
    "    \n",
    "    img_id = bg_img.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    # Convert and write JSON object to file\n",
    "    with open(f'{save_path}/annotations/{occlusion_level}/{img_id}.json', \"w\") as outfile: \n",
    "        json.dump(annotation, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3138f32b-47d2-44d2-9dff-51d5deb6463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libcom import color_transfer\n",
    "from libcom.utils.process_image import *\n",
    "from libcom.utils.environment import *\n",
    "from libcom import OPAScoreModel\n",
    "from libcom import get_composite_image\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "def generate_images(cate, bg_img_path, bg_w, bg_h, bg_bbox, save_real, save_unreal, record_file):\n",
    "\n",
    "    annotation = {}\n",
    "    \n",
    "    real_fg_img_path, real_fg_mask_path = get_realistic_occluder(cate)\n",
    "    img_id = bg_img_path.split('/')[-1].split('.')[0]\n",
    "     \n",
    "    score, real_ratio, op_fg_img_path, op_fg_mask_path, op_bbox, _, _ = get_optimal_location(real_fg_img_path, real_fg_mask_path, bg_img_path, bg_w, bg_h, bg_bbox, num_scales=16)\n",
    "    \n",
    "    if not score:\n",
    "        record_file.write(f'Skipped {bg_img_path}. Couldnt find optimal location.\\n')\n",
    "        # we couldnt find a possible foreground location, so we just skip everything\n",
    "        return\n",
    "\n",
    "    # write to a directory based on the level of occlusion\n",
    "    occlusion_level = None\n",
    "    for range_label, (min_occ, max_occ) in occlusion_ranges.items():\n",
    "        if min_occ <= real_ratio <= max_occ:\n",
    "            occlusion_level = range_label\n",
    "    \n",
    "    # first, we get a random occluder\n",
    "    unreal_fg_img_path, unreal_fg_mask_path = get_unrealistic_occluder()\n",
    "    \n",
    "    # get a bounding box and ratio for an occlusion that falls into the bin\n",
    "    random_fg_img_path, random_fg_mask_path, unreal_ratio, random_bbox = get_random_location(unreal_fg_img_path, unreal_fg_mask_path, bg_img_path, bg_w, bg_h, bg_bbox, occlusion_ranges[occlusion_level])\n",
    "    \n",
    "    if not random_fg_img_path:\n",
    "        record_file.write(f'Skipped {bg_img_path}. Couldnt find random location\\n')\n",
    "        # we couldnt find a reasonable foreground, so we skip writing out anything for both foreground and background\n",
    "        return\n",
    "    \n",
    "    # save the mask of the background image\n",
    "    background = './BG'\n",
    "    if not os.path.exists(background):\n",
    "        os.mkdir(background)\n",
    "    \n",
    "    bg_mask = bounding_box_to_mask(bg_img_path, op_bbox)\n",
    "    cv2.imwrite(f'{background}/{img_id}_mask.png', bg_mask)\n",
    "    \n",
    "    bg_img = cv2.imread(bg_img_path)\n",
    "    cv2.imwrite(f'{background}/{img_id}.JPEG', bg_img)\n",
    "    \n",
    "    foreground = './FG'\n",
    "    if not os.path.exists(foreground):\n",
    "        os.mkdir(foreground)\n",
    "        \n",
    "    with open('file_list.txt', 'a') as output:\n",
    "        output.write(occlusion_level + ' ' + bg_img_path + \"\\n\")\n",
    "    \n",
    "    fg_img = cv2.imread(op_fg_img_path)\n",
    "    fg_img_mask = cv2.imread(op_fg_mask_path)\n",
    "    cv2.imwrite(f'{foreground}/{img_id}.jpg', fg_img)\n",
    "    cv2.imwrite(f'{foreground}/{img_id}_mask.png', fg_img_mask)\n",
    "    \n",
    "    # realistic image\n",
    "    write_one_annotation(save_real, bg_img_path, cate, occlusion_level, real_ratio, real_fg_img_path, op_bbox, bg_bbox)\n",
    "    #res, _ = net(bg_img_path, [op_fg_img_path], [op_fg_mask_path], op_bbox, sample_steps=25, num_samples=3)\n",
    "    # TODO: find the best result in res, instead of just taking the last sample\n",
    "    #cv2.imwrite(f'{save_real}/images/{occlusion_level}/{img_id}.jpg', res[2])\n",
    "    \n",
    "    # unrealistic image\n",
    "    write_one_annotation(save_unreal, bg_img_path, cate, occlusion_level, unreal_ratio, unreal_fg_img_path, random_bbox, bg_bbox)\n",
    "    comp, _ = get_composite_image(random_fg_img_path, random_fg_mask_path, bg_img_path, random_bbox)\n",
    "    cv2.imwrite(f'{save_unreal}/images/{occlusion_level}/{img_id}.jpg', comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2655fa44-9c2d-4f2e-8475-f603bfd6e925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import BboxTools as bbt\n",
    "import os\n",
    "\n",
    "# the only reason we have bg_mask_dir is in case we need it for segmentation masks...\n",
    "def generate_dataset(cate, file_list, bg_img_dir, bg_anno_dir, save_real, save_unreal, tem):\n",
    "    \n",
    "    for file_name in file_list:\n",
    "        bg_w, bg_h, bg_bbox, flag_ = load_one_annotation(os.path.join(bg_anno_dir, file_name + '.mat'))\n",
    "\n",
    "        if flag_:\n",
    "            tem.write('Skipped %s for multi objects\\n' % file_name)\n",
    "            continue\n",
    "        \n",
    "        bg_img_path = os.path.join(bg_img_dir, file_name + '.JPEG')\n",
    "        \n",
    "        generate_images(cate, bg_img_path, bg_w, bg_h, bg_bbox, save_real, save_unreal, tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4ce0f1-a105-4249-9d14-93352872913d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = ['bus'] # , 'car', 'motorbike']\n",
    "\n",
    "real_save = './realistic'\n",
    "unreal_save = './unrealistic'\n",
    "\n",
    "path_to_original_pascal3dp = '/srv/PASCAL3D+_release1.1/'\n",
    "bg_list_path = path_to_original_pascal3dp + 'Image_sets/%s_imagenet_val.txt'\n",
    "bg_img_path = path_to_original_pascal3dp + 'Images/%s_imagenet'\n",
    "bg_anno_path = path_to_original_pascal3dp + 'Annotations/%s_imagenet'\n",
    "bg_mask_path = path_to_original_pascal3dp + 'obj_mask/%s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d52523ee-ca63-46ad-9c0c-5ae2ec6fe981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cate:  bus\n",
      "Start cate:  car\n",
      "Start cate:  motorbike\n"
     ]
    }
   ],
   "source": [
    "for dataset in [real_save, unreal_save]:\n",
    "    for data_type in ['images', 'annotations']:\n",
    "        for range_label in occlusion_ranges.keys():\n",
    "            os.makedirs(dataset + \"/\" + data_type + \"/\" + range_label, exist_ok=True)\n",
    "\n",
    "for cate in categories:\n",
    "    print('Start cate: ', cate)\n",
    "    tem = open('generating_record_%s_1030.txt' % cate, 'w')\n",
    "    file_list_ = open(bg_list_path % cate).readlines()\n",
    "    file_list_ = [tem.strip('\\n') for tem in file_list_]\n",
    "    bg_img_path_ = bg_img_path % cate\n",
    "    bg_anno_path_ = bg_anno_path % cate\n",
    "\n",
    "    generate_dataset(cate, file_list_, bg_img_path_, bg_anno_path_, real_save, unreal_save, tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35760aa-956d-4ea1-8ede-6dcc7f3653fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibCom Environment (Local)",
   "language": "python",
   "name": "libcom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
