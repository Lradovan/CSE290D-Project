{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ec652f-1cbc-4cc0-a78d-0ee3af39d9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openimages\n",
      "  Downloading openimages-0.0.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from openimages) (4.66.6)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from openimages) (2.32.3)\n",
      "Requirement already satisfied: boto3 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from openimages) (1.35.52)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from openimages) (1.5.3)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.52 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from boto3->openimages) (1.35.52)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from boto3->openimages) (0.10.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from boto3->openimages) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from botocore<1.36.0,>=1.35.52->boto3->openimages) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from botocore<1.36.0,>=1.35.52->boto3->openimages) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.52->boto3->openimages) (1.16.0)\n",
      "Collecting cvdata\n",
      "  Downloading cvdata-0.0.3-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from cvdata->openimages) (4.1.2.30)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from cvdata->openimages) (10.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from cvdata->openimages) (1.22.3)\n",
      "Collecting lxml\n",
      "  Downloading lxml-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.1 MB 7.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from pandas->openimages) (2024.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from requests->openimages) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from requests->openimages) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from requests->openimages) (2023.7.22)\n",
      "Installing collected packages: lxml, cvdata, openimages\n",
      "Successfully installed cvdata-0.0.3 lxml-5.3.0 openimages-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openimages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb189bd-f9b7-4d25-ad85-ba7a24990efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06  18:46:43 INFO Downloading 10 train images for class 'car'\n",
      "100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 23.64it/s]\n",
      "2024-11-06  18:46:44 INFO Creating 10 train annotations (pascal) for class 'car'\n",
      "100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 513.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'car': {'images_dir': './dest/dir/car/images',\n",
       "  'annotations_dir': './dest/dir/car/pascal'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openimages.download import download_dataset\n",
    "download_dataset(\"./dest/dir\", [\"Car\",], annotation_format=\"pascal\", limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd115461-ccab-4cff-bb72-4ed370b0ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding boxes for dest/dir/car/images/00005bf623ff1ac2.jpg: [37, 91, 997, 630]\n",
      "Bounding boxes for dest/dir/car/images/0001c6bf48e16ab2.jpg: [126, 434, 945, 875]\n",
      "Bounding boxes for dest/dir/car/images/0000575f5a03db70.jpg: [27, 111, 1006, 572]\n",
      "Bounding boxes for dest/dir/car/images/0001c8c65851276f.jpg: [67, 218, 923, 501]\n",
      "Bounding boxes for dest/dir/car/images/0000048549557964.jpg: [445, 536, 743, 725]\n",
      "Bounding boxes for dest/dir/car/images/0001c626b9afb50c.jpg: [112, 139, 908, 550]\n",
      "Bounding boxes for dest/dir/car/images/000228608388803f.jpg: [19, 156, 973, 715]\n",
      "Bounding boxes for dest/dir/car/images/0001124e2d5104e1.jpg: [16, 19, 962, 810]\n",
      "Bounding boxes for dest/dir/car/images/000096726fd6c6c8.jpg: [153, 124, 811, 767]\n",
      "Bounding boxes for dest/dir/car/images/00010bf498b64bab.jpg: [592, 287, 713, 386]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the path where your annotations are stored\n",
    "annotations_path = Path(\"./dest/dir/car/pascal\")\n",
    "images_path = Path(\"./dest/dir/car/images\")\n",
    "\n",
    "# Function to parse the XML and get bounding boxes\n",
    "def parse_anno(annotation_file):\n",
    "    tree = ET.parse(annotation_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    bboxes = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        class_name = obj.find(\"name\").text\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        width = int(root.find(\"size/width\").text)\n",
    "        height = int(root.find(\"size/height\").text)\n",
    "        x_min = int(bbox.find(\"xmin\").text)\n",
    "        y_min = int(bbox.find(\"ymin\").text)\n",
    "        x_max = int(bbox.find(\"xmax\").text)\n",
    "        y_max = int(bbox.find(\"ymax\").text)\n",
    "        bboxes.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "    return width, height, max(bboxes)\n",
    "\n",
    "# Example usage for one annotation file\n",
    "for annotation_file in annotations_path.glob(\"*.xml\"):\n",
    "    image_id = annotation_file.stem\n",
    "    image_file = images_path / f\"{image_id}.jpg\"\n",
    "    bboxes = get_bounding_box(annotation_file)\n",
    "    print(f\"Bounding boxes for {image_file}: {bboxes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53198e4d-0862-4f71-b590-22a2e71ec3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module 'xformers'. Proceeding without it.\n",
      "640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Libcom/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:258: LightningDeprecationWarning: `pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will be removed in v2.0.0. You can import it from `pytorch_lightning.utilities` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save result to  ./results/grid/000000000785.jpg\n",
      "end testing!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Just testing the FOPA code\n",
    "'''\n",
    "\n",
    "from libcom import FOPAHeatMapModel\n",
    "from libcom.utils.process_image import make_image_grid, draw_bbox_on_image\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "fg_img = '/home/lradovan/workspace/libcom/tests/source/foreground/1.jpg'\n",
    "fg_mask = '/home/lradovan/workspace/libcom/tests/source/foreground_mask/1.png'\n",
    "\n",
    "#test_set = get_test_list_fopa_heatmap()\n",
    "\n",
    "test_set = []\n",
    "for sample in dataset[5:6]:\n",
    "    print(sample.metadata.width)\n",
    "    test_set.append({'foreground': fg_img, 'foreground_mask': fg_mask, 'background': sample.filepath})\n",
    "    \n",
    "result_dir = './results/'\n",
    "net = FOPAHeatMapModel(device=0)\n",
    "\n",
    "for pair in test_set[:1]:\n",
    "    fg_img, fg_mask, bg_img = pair['foreground'], pair['foreground_mask'], pair['background']\n",
    "    bboxes, heatmaps = net(fg_img, fg_mask, bg_img, cache_dir=os.path.join(result_dir, 'cache'), heatmap_dir=os.path.join(result_dir, 'heatmap'))\n",
    "    img_name  = os.path.basename(bg_img).replace('.png', '.jpg')\n",
    "    bbox = bboxes[0]\n",
    "    bg_img  = draw_bbox_on_image(bg_img, [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n",
    "    grid_img  = make_image_grid([bg_img, fg_img, heatmaps[0]])\n",
    "    os.makedirs(os.path.join(result_dir, 'grid'), exist_ok=True)\n",
    "    res_path  = os.path.join(result_dir, 'grid', img_name)\n",
    "    cv2.imwrite(res_path, grid_img)\n",
    "    print('save result to ', res_path)\n",
    "print(f'end testing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62859c25-6ef3-4d75-84fb-d24ba8627537",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get overlap percentage\n",
    "'''\n",
    "def overlap_ratio(occluder_bb, occludee_bb):\n",
    "\n",
    "    #top left and bottom right points\n",
    "    occluder_x1, occluder_y1, occluder_x2, occluder_y2 = occluder_bb\n",
    "    occludee_x1, occludee_y1, occludee_x2, occludee_y2 = occludee_bb\n",
    "\n",
    "    # area of the foreground object\n",
    "    occludee_area = (occludee_x2 - occludee_x1) * (occludee_y2 - occludee_y1)\n",
    "\n",
    "    # area of the background object being covered by the foreground object\n",
    "    overlap_area = max(0, min(occludee_x2, occluder_x2) - max(occludee_x1, occluder_x1)) * max(0, min(occludee_y2, occluder_y2) - max(occludee_y1, occluder_y1))\n",
    "\n",
    "    # overlap over the total background object area\n",
    "    return overlap_area / occludee_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e40a3046-ebed-4deb-b3ce-5d75013792ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "'''\n",
    "Get a list of randomly chosen bounding boxes to occlude the background object above some threshold\n",
    "This can be improved if we know the foreground image has to be some base scale to allow for above threshold occlusion\n",
    "'''\n",
    "def get_bbox_list(bg_bbox, bg_w, bg_h, fg_w, fg_h):\n",
    "\n",
    "    bboxes = []\n",
    "\n",
    "    occludee_x1 = bg_bbox[0]\n",
    "    occludee_y1 = bg_bbox[1] \n",
    "    occludee_x2 = bg_bbox[2]\n",
    "    occludee_y2 = bg_bbox[3]\n",
    "\n",
    "    num_boxes = 5 # iterate over multiple boxes\n",
    "    overlap_threshold = .2 # ensure a minimum amount of overlap\n",
    "\n",
    "    # print(bg_bbox, fg_w, fg_h)\n",
    "    \n",
    "    for _ in range(num_boxes):\n",
    "        # top left corner of the occluder bounding box:\n",
    "\n",
    "        occluder_x1 = random.randint(max(0, occludee_x1 - fg_w), occludee_x2) # overlapping in the x-direction\n",
    "        occluder_y1 = random.randint(max(0, occludee_y1 - fg_h), occludee_y2) # overlapping in the y-direction\n",
    "\n",
    "        # TODO: Fix so doesnt exceed background image\n",
    "        \n",
    "        occluder_x2 = occluder_x1 + fg_w\n",
    "        occluder_y2 = occluder_y1 + fg_h\n",
    "\n",
    "        # Maybe this will fix sizing error??? (IT DOES)\n",
    "        if occluder_x2 > bg_w or occluder_y2 > bg_h:\n",
    "            continue\n",
    "\n",
    "        occluder_bb = [occluder_x1, occluder_y1, occluder_x2, occluder_y2]\n",
    "        occluded_ratio = overlap_ratio(occluder_bb, bg_bbox)\n",
    "\n",
    "        if occluded_ratio >= overlap_threshold:\n",
    "            bboxes.append([occluder_x1, occluder_y1, occluder_x2, occluder_y2])\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bcddcea-517d-4f4c-ae09-73ace7e0a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "returns the score, composite image, and compositive mask. \n",
    "num scales is the number of different foreground scales to try.\n",
    "'''\n",
    "\n",
    "def get_optimal_location(fg_img, fg_mask, bg_img, bg_w, bg_h, bg_bbox, num_scales):\n",
    "    cache_dir = './cache'\n",
    "\n",
    "    # from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "    scaled_fg_dir, scaled_mask_dir, csv_path = prepare_multi_fg_scales(cache_dir, fg_img, fg_mask, bg_img, num_scales)\n",
    "\n",
    "    score = 0\n",
    "    res = [-1, -1]\n",
    "    \n",
    "    # iterate over the different foreground scales\n",
    "    with open(csv_path, mode='r', newline='') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            fg_name   = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            mask_name = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            scale     = row['scale']\n",
    "            fg_w = int(row['newWidth'])\n",
    "            fg_h = int(row['newHeight'])\n",
    "            \n",
    "            save_name = fg_name.split(\".\")[0] + '_' + str(scale) + '.jpg'\n",
    "            bg_img    = read_image_pil(bg_img)\n",
    "            fg_img    = read_image_pil(os.path.join(scaled_fg_dir, fg_name))\n",
    "            fg_mask   = read_mask_pil(os.path.join(scaled_mask_dir, mask_name))\n",
    "            bbox_list = get_bbox_list(bg_bbox, bg_w, bg_h, fg_w, fg_h)\n",
    "    \n",
    "            for bbox in bbox_list:\n",
    "                comp, comp_mask = get_composite_image(fg_img, fg_mask, bg_img, bbox)\n",
    "                bbox_score = net(comp, comp_mask)\n",
    "                if bbox_score > score:\n",
    "                    res = comp, comp_mask\n",
    "                    score = bbox_score\n",
    "\n",
    "        return score, res[0], res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72bb5c37-f15f-4698-a0aa-7183cc4f0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Right now this just takes does one specific foreground image (teddy bear), and one background image (skier)\n",
    "'''\n",
    "\n",
    "from libcom.utils.process_image import *\n",
    "from libcom.utils.environment import *\n",
    "from libcom import OPAScoreModel\n",
    "from libcom import get_composite_image\n",
    "from libcom.utils.process_image import make_image_grid\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image\n",
    "from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "\n",
    "net = OPAScoreModel(device=0, model_type='SimOPA')\n",
    "\n",
    "# for each scale, take the highest OPA score\n",
    "fg_scale_num = 16\n",
    "\n",
    "# trying with just one foreground image (teddy bear) and one background image (skier)\n",
    "foreground_image = '/home/lradovan/workspace/libcom/tests/source/foreground/8.jpg'\n",
    "foreground_mask = '/home/lradovan/workspace/libcom/tests/source/foreground_mask/8.png'\n",
    "\n",
    "# Define the path where your annotations are stored\n",
    "bg_annotations_path = Path(\"./dest/dir/car/pascal\")\n",
    "bg_images_path = Path(\"./dest/dir/car/images\")\n",
    "\n",
    "for annotation_file in annotations_path.glob(\"*.xml\"):\n",
    "    image_id = annotation_file.stem\n",
    "    bg_img = os.path.join(bg_images_path, f\"{image_id}.jpg\")\n",
    "    bg_w, bg_h, bg_bbox = parse_anno(annotation_file)\n",
    "    score, comp, comp_mask = get_optimal_location(foreground_image, foreground_mask, bg_img, bg_w, bg_h, bg_bbox, num_scales=16)\n",
    "    if(score):\n",
    "        grid_img  = make_image_grid([comp, comp_mask])\n",
    "        cv2.imwrite(f'./results/composite_{image_id}.jpg', grid_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1606a709-d9e7-4ed1-a9b7-0b0c9858e8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibCom Environment",
   "language": "python",
   "name": "libcom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
