{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bf80cc-aee0-466c-abc0-f9136748e4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***Python 3.8 Deprecation Notice***\n",
      "Python 3.8 will no longer be supported in new releases after October 1, 2024.\n",
      "Please upgrade to Python 3.9 or later.\n",
      "For additional details please see https://deprecation.voxel51.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to '/home/lradovan/fiftyone/coco-2017/validation' if necessary\n",
      "Found annotations at '/home/lradovan/fiftyone/coco-2017/raw/instances_val2017.json'\n",
      "Sufficient images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***Python 3.8 Deprecation Notice***\n",
      "Python 3.8 will no longer be supported in new releases after October 1, 2024.\n",
      "Please upgrade to Python 3.9 or later.\n",
      "For additional details please see https://deprecation.voxel51.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing dataset 'coco-2017-validation-10'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Load a small dataset\n",
    "dataset = fo.zoo.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"detections\"],\n",
    "    max_samples=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53198e4d-0862-4f71-b590-22a2e71ec3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "save result to  ./results/grid/000000000785.jpg\n",
      "end testing!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Just testing the FOPA code\n",
    "'''\n",
    "\n",
    "from libcom import FOPAHeatMapModel\n",
    "from libcom.utils.process_image import make_image_grid, draw_bbox_on_image\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "fg_img = '/home/lradovan/workspace/libcom/tests/source/foreground/1.jpg'\n",
    "fg_mask = '/home/lradovan/workspace/libcom/tests/source/foreground_mask/1.png'\n",
    "\n",
    "#test_set = get_test_list_fopa_heatmap()\n",
    "\n",
    "test_set = []\n",
    "for sample in dataset[5:6]:\n",
    "    print(sample.metadata.width)\n",
    "    test_set.append({'foreground': fg_img, 'foreground_mask': fg_mask, 'background': sample.filepath})\n",
    "    \n",
    "result_dir = './results/'\n",
    "net = FOPAHeatMapModel(device=0)\n",
    "\n",
    "for pair in test_set[:1]:\n",
    "    fg_img, fg_mask, bg_img = pair['foreground'], pair['foreground_mask'], pair['background']\n",
    "    bboxes, heatmaps = net(fg_img, fg_mask, bg_img, cache_dir=os.path.join(result_dir, 'cache'), heatmap_dir=os.path.join(result_dir, 'heatmap'))\n",
    "    img_name  = os.path.basename(bg_img).replace('.png', '.jpg')\n",
    "    bbox = bboxes[0]\n",
    "    bg_img  = draw_bbox_on_image(bg_img, [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n",
    "    grid_img  = make_image_grid([bg_img, fg_img, heatmaps[0]])\n",
    "    os.makedirs(os.path.join(result_dir, 'grid'), exist_ok=True)\n",
    "    res_path  = os.path.join(result_dir, 'grid', img_name)\n",
    "    cv2.imwrite(res_path, grid_img)\n",
    "    print('save result to ', res_path)\n",
    "print(f'end testing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "829be8b3-4a4e-4ee8-9c0f-b17172f3d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gets the largest bounding box from a background image\n",
    "'''\n",
    "def get_bounding_box(sample):\n",
    "    detections = sample.ground_truth.detections\n",
    "    if len(detections) > 0:\n",
    "        print(f\"\\nImage path: {sample.filepath}\")\n",
    "        \n",
    "        # Find largest bounding box\n",
    "        largest_det = max(detections, key=lambda d: get_box_area(d.bounding_box))\n",
    "\n",
    "        # get bbox\n",
    "        bbox = largest_det.bounding_box\n",
    "        width = sample.metadata.width\n",
    "        height = sample.metadata.height\n",
    "        \n",
    "        x1 = int(bbox[0] * width)\n",
    "        y1 = int(bbox[1] * height)\n",
    "        x2 = int((bbox[0] + bbox[2]) * width)\n",
    "        y2 = int((bbox[1] + bbox[3]) * height)\n",
    "\n",
    "    return [x1, y1, x2, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19cc827-9bce-4493-aa89-4db9a1047757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a box of the form [x1, x2, y1, y2]\n",
    "def get_box_area(box):\n",
    "    return (box[1] - box[0]) * (box[3] - box[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62859c25-6ef3-4d75-84fb-d24ba8627537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get overlap / background subject\n",
    "def overlap_ratio(occluder_bb, occludee_bb):\n",
    "\n",
    "    #top left and bottom right points\n",
    "    occluder_x1, occluder_y1, occluder_x2, occluder_y2 = occluder_bb\n",
    "    occludee_x1, occludee_y1, occludee_x2, occludee_y2 = occludee_bb\n",
    "\n",
    "    # area of the foreground object\n",
    "    occludee_area = (occludee_x2 - occludee_x1) * (occludee_y2 - occludee_y1)\n",
    "\n",
    "    # area of the background object being covered by the foreground object\n",
    "    overlap_area = max(0, min(occludee_x2, occluder_x2) - max(occludee_x1, occluder_x1)) * max(0, min(occludee_y2, occluder_y2) - max(occludee_y1, occluder_y1))\n",
    "\n",
    "    # overlap over the total background object area\n",
    "    return overlap_area / occludee_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e40a3046-ebed-4deb-b3ce-5d75013792ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "'''\n",
    "Get a list of randomly chosen bounding boxes to occlude the background object above some threshold\n",
    "This can be improved if we know the foreground image has to be some base scale to allow for above threshold occlusion\n",
    "'''\n",
    "def get_bbox_list(bg_bbox, bg_w, bg_h, fg_w, fg_h):\n",
    "\n",
    "    bboxes = []\n",
    "\n",
    "    occludee_x1 = bg_bbox[0]\n",
    "    occludee_y1 = bg_bbox[1] \n",
    "    occludee_x2 = bg_bbox[2]\n",
    "    occludee_y2 = bg_bbox[3]\n",
    "\n",
    "    num_boxes = 5 # iterate over multiple boxes\n",
    "    overlap_threshold = .2 # ensure a minimum amount of overlap\n",
    "\n",
    "    # print(bg_bbox, fg_w, fg_h)\n",
    "    \n",
    "    for _ in range(num_boxes):\n",
    "        # top left corner of the occluder bounding box:\n",
    "\n",
    "        occluder_x1 = random.randint(max(0, occludee_x1 - fg_w), occludee_x2) # overlapping in the x-direction\n",
    "        occluder_y1 = random.randint(max(0, occludee_y1 - fg_h), occludee_y2) # overlapping in the y-direction\n",
    "\n",
    "        # TODO: Fix so doesnt exceed background image\n",
    "        \n",
    "        occluder_x2 = occluder_x1 + fg_w\n",
    "        occluder_y2 = occluder_y1 + fg_h\n",
    "\n",
    "        # Maybe this will fix sizing error??? (IT DOES)\n",
    "        if occluder_x2 > bg_w or occluder_y2 > bg_h:\n",
    "            continue\n",
    "\n",
    "        occluder_bb = [occluder_x1, occluder_y1, occluder_x2, occluder_y2]\n",
    "        occluded_ratio = overlap_ratio(occluder_bb, bg_bbox)\n",
    "\n",
    "        if occluded_ratio >= overlap_threshold:\n",
    "            bboxes.append([occluder_x1, occluder_y1, occluder_x2, occluder_y2])\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bca9ed84-98dd-4fbd-9451-663e5e02061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/bcmi/libcom/blob/main/libcom/fopa_heat_map/source/prepare_multi_fg_scales.py\n",
    "\n",
    "# I was just using this to confirm that the width and height put into the CSV is equivalent to the scaled foreground with and height\n",
    "# - it is\n",
    "# will delete soon\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "fg_scale_num = 16\n",
    "\n",
    "def fill_image_by_mask(image, mask, fill_pixel=0, thresh=127):\n",
    "    image = np.asarray(image).copy()\n",
    "    mask  = np.asarray(mask)\n",
    "    fill_img = (np.ones_like(image) * fill_pixel).astype(np.uint8)\n",
    "    image = np.where(mask > thresh, image, fill_img)\n",
    "    return Image.fromarray(image)\n",
    "\n",
    "# I added the foreground bounding box to the list of arguments\n",
    "def prepare_multi_fg_scales(cache_dir, fg_path, mask_path, bg_path, fg_bb, fg_scale_num):\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fg_name   = os.path.splitext(os.path.basename(fg_path))[0]\n",
    "    bg_name   = os.path.splitext(os.path.basename(bg_path))[0]\n",
    "    fg_scales = list(range(1, fg_scale_num+1))\n",
    "    fg_scales = [i/(1+fg_scale_num+1) for i in fg_scales]\n",
    "\n",
    "    # -- code I added in ----\n",
    "    fg_bb_width = fg_bb[2] - fg_bb[0]  # original bounding box width\n",
    "    fg_bb_height = fg_bb[3] - fg_bb[1] # original bounding box height\n",
    "    \n",
    "    scaled_fg_dir   = os.path.join(cache_dir, f'fg_{fg_scale_num}scales')\n",
    "    scaled_mask_dir = os.path.join(cache_dir, f'mask_{fg_scale_num}scales')    \n",
    "    csv_file = os.path.join(cache_dir, f'{fg_scale_num}scales.csv')\n",
    "    os.makedirs(scaled_fg_dir,   exist_ok=True)\n",
    "    os.makedirs(scaled_mask_dir, exist_ok=True)\n",
    "\n",
    "    file = open(csv_file, mode='w', newline='')\n",
    "    writer = csv.writer(file)\n",
    "    csv_head = ['fg_name', 'mask_name', 'bg_name', 'scale', 'newWidth', 'newHeight', 'bbWidth', 'bbHeight', 'pos_label', 'neg_label']\n",
    "    writer.writerow(csv_head)\n",
    "\n",
    "    bg_img = Image.open(bg_path).convert(\"RGB\")  \n",
    "    bg_img_aspect = bg_img.height / bg_img.width\n",
    "    fg_tocp   = Image.open(fg_path).convert(\"RGB\")\n",
    "    mask_tocp = Image.open(mask_path).convert(\"RGB\")\n",
    "    fg_tocp   = fill_image_by_mask(fg_tocp, mask_tocp)\n",
    "    fg_tocp_aspect = fg_tocp.height / fg_tocp.width\n",
    "    \n",
    "    for fg_scale in fg_scales:\n",
    "        if fg_tocp_aspect > bg_img_aspect:\n",
    "            # bounding box scaling!\n",
    "            bb_h = int(bg_img.height * fg_scale)\n",
    "            bb_w = int(bb_h / fg_bb_height * fg_bb_width)\n",
    "            \n",
    "            new_height = int(bg_img.height * fg_scale)\n",
    "            new_width  = int(new_height / fg_tocp.height * fg_tocp.width)\n",
    "        else:\n",
    "            # bounding box scaling!\n",
    "            bb_w = int(bg_img.width * fg_scale)\n",
    "            fg_h = int(bb_w / fg_bb_width * fg_bb_height)\n",
    "            \n",
    "            new_width  = int(bg_img.width * fg_scale)\n",
    "            new_height = int(new_width / fg_tocp.width * fg_tocp.height)\n",
    "        \n",
    "        top    = int((bg_img.height - new_height) / 2)\n",
    "        bottom = top + new_height\n",
    "        left   = int((bg_img.width - new_width) / 2)\n",
    "        right  = left + new_width\n",
    "        \n",
    "        fg_img_ = np.asarray(fg_tocp.resize((new_width, new_height)))\n",
    "        mask_   = np.asarray(mask_tocp.resize((new_width, new_height)))\n",
    "        fg_img  = np.zeros((bg_img.height, bg_img.width, 3), dtype=np.uint8) \n",
    "        mask    = np.zeros((bg_img.height, bg_img.width, 3), dtype=np.uint8) \n",
    "        fg_img[top:bottom, left:right, :] = fg_img_\n",
    "        mask[top:bottom, left:right, :] = mask_\n",
    "        fg_img = Image.fromarray(fg_img.astype(np.uint8))\n",
    "        mask = Image.fromarray(mask.astype(np.uint8))\n",
    "        \n",
    "        basename = f'{fg_name}_{bg_name}_{new_width}_{new_height}.jpg'\n",
    "        fg_img_path = os.path.join(scaled_fg_dir, basename)\n",
    "        mask_path = os.path.join(scaled_mask_dir, basename)\n",
    "        fg_img.save(fg_img_path)\n",
    "        mask.save(mask_path)\n",
    "\n",
    "        # Instead of new_width and new_height for the image, lets try to take the scaled bounding box's height and width\n",
    "        writer.writerow([os.path.basename(fg_path), \n",
    "                         os.path.basename(mask_path), \n",
    "                         os.path.basename(bg_path), \n",
    "                         fg_scale, new_width, new_height, bb_w, bb_h,\n",
    "                         None, None])\n",
    "    file.close()  \n",
    "    csv_data = []\n",
    "    with open(csv_file, mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row['pos_label']==\"\":\n",
    "                row['pos_label'] = [[0,0]]\n",
    "            if row['neg_label']==\"\":\n",
    "                row['neg_label'] = [[0,0]]\n",
    "            csv_data.append(row)\n",
    "    return scaled_fg_dir, scaled_mask_dir, csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72bb5c37-f15f-4698-a0aa-7183cc4f0210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image path: /home/lradovan/fiftyone/coco-2017/validation/data/000000000785.jpg\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[[361, 66, 533, 231], [395, 186, 567, 351]]\n",
      "[[224, 164, 420, 352], [373, 152, 569, 340]]\n",
      "[[194, 143, 415, 355], [146, 196, 367, 408]]\n",
      "[[359, 122, 605, 358], [130, 186, 376, 422]]\n",
      "[[239, 3, 509, 262], [100, 64, 370, 323], [107, 24, 377, 283]]\n",
      "[[115, 135, 410, 418]]\n",
      "[[198, 113, 517, 419]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "0.9997072815895081\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Right now this just takes does one specific foreground image (teddy bear), and one background image (skier)\n",
    "The output goes to ./results/best.jpg\n",
    "'''\n",
    "\n",
    "from libcom.utils.process_image import *\n",
    "from libcom.utils.environment import *\n",
    "from libcom import OPAScoreModel\n",
    "from libcom import get_composite_image\n",
    "from libcom.utils.process_image import make_image_grid\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image\n",
    "from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "\n",
    "net = OPAScoreModel(device=0, model_type='SimOPA')\n",
    "\n",
    "# for each scale, take the highest OPA score\n",
    "fg_scale_num = 16\n",
    "\n",
    "# trying with just one foreground image (teddy bear) and one background image (skier)\n",
    "foreground_image = '/home/lradovan/workspace/libcom/tests/source/foreground/1.jpg'\n",
    "foreground_mask = '/home/lradovan/workspace/libcom/tests/source/foreground_mask/1.png'\n",
    "\n",
    "# this is the bounding box specific to the teddy bear\n",
    "fg_bb = [1000, 895, 1480, 1355]\n",
    "\n",
    "bg_imgs = []\n",
    "for sample in dataset[5:6]:\n",
    "    bg_imgs.append([sample.filepath, get_bounding_box(sample), sample.metadata.width, sample.metadata.height])\n",
    "\n",
    "background_image = bg_imgs[0][0]\n",
    "\n",
    "cache_dir = './cache'\n",
    "\n",
    "# from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "scaled_fg_dir, scaled_mask_dir, csv_path = prepare_multi_fg_scales(cache_dir, foreground_image, foreground_mask, background_image, fg_scale_num)\n",
    " \n",
    "# iterate over the different foreground scales\n",
    "with open(csv_path, mode='r', newline='') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    score = 0\n",
    "    res = [-1, -1]\n",
    "    for row in csv_reader:\n",
    "        fg_name   = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "        mask_name = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "        scale     = row['scale']\n",
    "        fg_w = int(row['newWidth'])\n",
    "        fg_h = int(row['newHeight'])\n",
    "        \n",
    "        save_name = fg_name.split(\".\")[0] + '_' + str(scale) + '.jpg'\n",
    "\n",
    "        bg_img    = read_image_pil(background_image)\n",
    "        fg_img    = read_image_pil(os.path.join(scaled_fg_dir, fg_name))\n",
    "        fg_mask   = read_mask_pil(os.path.join(scaled_mask_dir, mask_name))\n",
    "        bbox_list = get_bbox_list(bg_imgs[0][1], bg_imgs[0][2], bg_imgs[0][3], fg_w, fg_h)\n",
    "\n",
    "        print(bbox_list)\n",
    "\n",
    "        for bbox in bbox_list:\n",
    "            try:\n",
    "                comp, comp_mask = get_composite_image(fg_img, fg_mask, bg_img, bbox)\n",
    "                bbox_score = net(comp, comp_mask)\n",
    "                if bbox_score > score:\n",
    "                    res = comp, comp_mask\n",
    "                    score = bbox_score\n",
    "            except:\n",
    "                print(\"Sizing issues!\")\n",
    "\n",
    "    print(score)\n",
    "    grid_img  = make_image_grid(res)\n",
    "    cv2.imwrite('./results/best.jpg', grid_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibCom Environment",
   "language": "python",
   "name": "libcom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
