{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb8bb579-b79e-4a69-bfe0-50a0f0dcbb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "'''\n",
    "Important paths\n",
    "'''\n",
    "path_to_original_pascal3dp = '/srv/PASCAL3D+_release1.1/'\n",
    "\n",
    "small_occluder_path = '/srv/occluder_libs_test_small.npz'\n",
    "medium_occluder_path = '/srv/occluder_libs_test_medium.npz'\n",
    "large_occluder_path = '/srv/occluder_libs_test_large.npz'\n",
    "\n",
    "# just for now...\n",
    "occluder_path = '/srv/occluder_libs_test_medium.npz'\n",
    "\n",
    "bg_list_path = path_to_original_pascal3dp + 'Image_sets/%s_imagenet_val.txt'\n",
    "bg_img_path = path_to_original_pascal3dp + 'Images/%s_imagenet'\n",
    "bg_anno_path = path_to_original_pascal3dp + 'Annotations/%s_imagenet'\n",
    "bg_mask_path = path_to_original_pascal3dp + 'obj_mask/%s'\n",
    "\n",
    "path_save = './results'\n",
    "save_img_path = path_save + '/images'\n",
    "save_anno_path = path_save + '/annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21f821bb-27fa-4292-9d86-181f90d27a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['bicycle', 'bus', 'car', 'motorbike', 'train']\n",
    "\n",
    "occlusion_ranges = {\n",
    "    \"low\": (0.2, 0.4),\n",
    "    \"medium\": (0.4, 0.6),\n",
    "    \"high\": (0.6, 0.8)\n",
    "}\n",
    "\n",
    "dataset = {\"low\": [], \"medium\": [], \"high\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f00d29f1-e78a-4b3e-bf65-5f2da434fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def load_one_annotation(anno_path):\n",
    "    a = scipy.io.loadmat(anno_path)\n",
    "    # I added the astype int here....\n",
    "    bbox_ = a['record'][0][0][1][0][0][1][0].astype(int)\n",
    "    w = a['record']['size'][0][0][0][0][0]\n",
    "    h = a['record']['size'][0][0][0][0][1]\n",
    "    num_obj = len(a['record'][0][0][1][0])\n",
    "    return w, h, bbox_, num_obj != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1c62389-e92d-470f-b1a3-86e1b646d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get overlap percentage based on bounding boxes\n",
    "'''\n",
    "def overlap_ratio(occluder_bb, occludee_bb):\n",
    "\n",
    "    #top left and bottom right points\n",
    "    occluder_x1, occluder_y1, occluder_x2, occluder_y2 = occluder_bb\n",
    "    occludee_x1, occludee_y1, occludee_x2, occludee_y2 = occludee_bb\n",
    "\n",
    "    # area of the foreground object\n",
    "    occludee_area = (occludee_x2 - occludee_x1) * (occludee_y2 - occludee_y1)\n",
    "\n",
    "    # area of the background object being covered by the foreground object\n",
    "    overlap_area = max(0, min(occludee_x2, occluder_x2) - max(occludee_x1, occluder_x1)) * max(0, min(occludee_y2, occluder_y2) - max(occludee_y1, occluder_y1))\n",
    "\n",
    "    # overlap over the total background object area\n",
    "    return overlap_area / occludee_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e96a0873-b634-49dd-a8e1-1965c12dfb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "'''\n",
    "Get a list of randomly chosen bounding boxes to occlude the background object above some threshold\n",
    "This can be improved if we know the foreground image has to be some base scale to allow for above threshold occlusion\n",
    "'''\n",
    "def get_bbox_list(bg_bbox, fg_mask, bg_w, bg_h, fg_w, fg_h):\n",
    "\n",
    "    random.seed(time.time())\n",
    "\n",
    "    bboxes = []\n",
    "    occludee_x1 = bg_bbox[0]\n",
    "    occludee_y1 = bg_bbox[1] \n",
    "    occludee_x2 = bg_bbox[2]\n",
    "    occludee_y2 = bg_bbox[3]\n",
    "    num_boxes = 20\n",
    "    \n",
    "    for _ in range(num_boxes):\n",
    "\n",
    "        occluder_x1 = random.randint(max(0, occludee_x1 - fg_w), occludee_x2) # overlapping in the x-direction\n",
    "        occluder_y1 = random.randint(max(0, occludee_y1 - fg_h), occludee_y2) # overlapping in the y-direction\n",
    "\n",
    "        # TODO: Fix so doesnt exceed background image\n",
    "        \n",
    "        occluder_x2 = occluder_x1 + fg_w\n",
    "        occluder_y2 = occluder_y1 + fg_h\n",
    "\n",
    "        if occluder_x2 > bg_w or occluder_y2 > bg_h:\n",
    "            continue\n",
    "\n",
    "        occluder_bb = [occluder_x1, occluder_y1, occluder_x2, occluder_y2]\n",
    "        occluded_ratio = overlap_ratio(occluder_bb, bg_bbox)\n",
    "\n",
    "        if occluded_ratio >= .20:\n",
    "            bboxes.append((occluded_ratio, [occluder_x1, occluder_y1, occluder_x2, occluder_y2]))\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5bce983-70a5-4382-b39f-f3c477f6ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "returns the score, composite image, and compositive mask. \n",
    "num scales is the number of different foreground scales to try.\n",
    "'''\n",
    "from libcom import OPAScoreModel\n",
    "\n",
    "def get_optimal_location(fg_img, fg_mask, bg_img, bg_w, bg_h, bg_bbox, num_scales):\n",
    "\n",
    "    net = OPAScoreModel(device=0, model_type='SimOPA')\n",
    "    cache_dir = './cache'\n",
    "\n",
    "    # from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "    scaled_fg_dir, scaled_mask_dir, csv_path = prepare_multi_fg_scales(cache_dir, fg_img, fg_mask, bg_img, 16)\n",
    "\n",
    "    score = 0\n",
    "    ratio = 0\n",
    "    optimal_bbox = None\n",
    "    best_fg = None\n",
    "    best_mask = None\n",
    "    best_comp = None \n",
    "    best_comp_mask = None\n",
    "    \n",
    "    with open(csv_path, mode='r', newline='') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            fg_name   = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            mask_name = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            fg_w = int(row['newWidth'])\n",
    "            fg_h = int(row['newHeight'])\n",
    "\n",
    "            # why are we doing this...\n",
    "            bg_img    = read_image_pil(bg_img)\n",
    "            bbox_list = get_bbox_list(bg_bbox, fg_mask, bg_w, bg_h, fg_w, fg_h)\n",
    "\n",
    "            fg_img = os.path.join(scaled_fg_dir, fg_name)\n",
    "            fg_mask = os.path.join(scaled_mask_dir, mask_name)\n",
    "\n",
    "            for occ_ratio, bbox in bbox_list:\n",
    "                comp, comp_mask = get_composite_image(fg_img, fg_mask, bg_img, bbox)\n",
    "                bbox_score = net(comp, comp_mask)\n",
    "                if bbox_score > score:\n",
    "                    best_fg = fg_img\n",
    "                    best_mask = fg_mask\n",
    "                    optimal_bbox = bbox\n",
    "                    best_comp = comp\n",
    "                    best_comp_mask = comp_mask\n",
    "                    score = bbox_score\n",
    "                    ratio = occ_ratio\n",
    "\n",
    "        return score, ratio, best_fg, best_mask, optimal_bbox, best_comp, best_comp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "268561c1-e56f-4a6e-96ec-a111b075838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "'''\n",
    "Get a random occluder and correspondiong mask\n",
    "'''\n",
    "def get_occluder():\n",
    "    data = np.load(occluder_path, allow_pickle=True)\n",
    "\n",
    "    random.seed(time.time())\n",
    "\n",
    "    os.makedirs('./occluders', exist_ok=True)\n",
    "    \n",
    "    i = random.randint(0, len(data['images']))\n",
    "    occ_img = f'./occluders/fg_img_{i}.jpg'\n",
    "    occ_mask = f'./occluders/fg_mask_{i}.png'\n",
    "\n",
    "    image = data['images'][i]\n",
    "    mask = data['masks'][i]\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "        \n",
    "    cv2.imwrite(occ_img, image)\n",
    "    cv2.imwrite(occ_mask, mask)\n",
    "\n",
    "    return occ_img, occ_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3138f32b-47d2-44d2-9dff-51d5deb6463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libcom import color_transfer\n",
    "from libcom.utils.process_image import *\n",
    "from libcom.utils.environment import *\n",
    "from libcom import OPAScoreModel\n",
    "from libcom import get_composite_image\n",
    "from libcom.utils.process_image import make_image_grid\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image\n",
    "from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "from libcom import Mure_ObjectStitchModel\n",
    "from libcom import ControlComModel\n",
    "import json\n",
    "\n",
    "def generate_composite_image(cate, bg_img, bg_w, bg_h, bg_bbox, save_img_path):\n",
    "\n",
    "    net = Mure_ObjectStitchModel(device=0, sampler='plms')\n",
    "\n",
    "    # maybe a list isnt necessary here? They do one anntotation for each of the occlusion ratios in OccludedPascal3D+\n",
    "    annotation = {}\n",
    "\n",
    "    # fg_mask is a path to an image here.... but bg_mask is a numpy array!\n",
    "    fg_img, fg_mask = get_occluder()\n",
    "\n",
    "    occluder_path = fg_img\n",
    "\n",
    "    img_id = bg_img.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    score, ratio, fg_img, fg_mask, bbox, comp, comp_mask = get_optimal_location(fg_img, fg_mask, bg_img, bg_w, bg_h, bg_bbox, num_scales=16)\n",
    "\n",
    "    # x1, y1, x2, y2 = bg_bbox\n",
    "\n",
    "    annotation['box'] = bg_bbox.tolist() \n",
    "    annotation['ratio'] = ratio\n",
    "    annotation['occluder_box'] = bbox\n",
    "    annotation['occluder_path'] = occluder_path\n",
    "    annotation['source'] = bg_img\n",
    "    annotation['cate'] = cate\n",
    "\n",
    "    # write to a directory based on the level of occlusion\n",
    "    occlusion_level = None\n",
    "    for range_label, (min_occ, max_occ) in occlusion_ranges.items():\n",
    "        if min_occ <= ratio <= max_occ:\n",
    "            occlusion_level = range_label\n",
    "            \n",
    "    if(score):\n",
    "        res, show_fg_img = net(bg_img, [fg_img], [fg_mask], bbox, sample_steps=25, num_samples=3)\n",
    "\n",
    "        # Convert and write JSON object to file\n",
    "        with open(f'{save_anno_path}/{occlusion_level}/{img_id}.json', \"w\") as outfile: \n",
    "            json.dump(annotation, outfile)\n",
    "        \n",
    "        # TODO: find the best result in res, instead of just taking the last sample!!!!\n",
    "        cv2.imwrite(f'{save_img_path}/{occlusion_level}/{img_id}.jpg', res[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b12fc27-ed49-4054-b70e-f934f343fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import BboxTools as bbt\n",
    "import os\n",
    "\n",
    "# the only reason we have bg_mask_dir is in case we need it for segmentation masks...\n",
    "def generate_dataset(cate, file_list, bg_img_dir, bg_anno_dir, save_img_dir, save_anno_dir, record_file):\n",
    "\n",
    "    os.makedirs(save_img_dir, exist_ok=True)\n",
    "    os.makedirs(save_anno_dir, exist_ok=True)\n",
    "\n",
    "    # make a different directory for each range\n",
    "    for range_label in occlusion_ranges.keys():\n",
    "        os.makedirs(save_img_dir + \"/\" + range_label, exist_ok=True)\n",
    "        os.makedirs(save_anno_dir + \"/\" + range_label, exist_ok=True)\n",
    "    \n",
    "    for file_name in file_list[9:10]:\n",
    "        bg_w, bg_h, bg_bbox, flag_ = load_one_annotation(os.path.join(bg_anno_dir, file_name + '.mat'))\n",
    "\n",
    "        if flag_:\n",
    "            record_file.write('Skipped %s for multi objects\\n' % file_name)\n",
    "            continue\n",
    "\n",
    "        bg_img = os.path.join(bg_img_dir, file_name + '.JPEG')\n",
    "        # bg_mask = np.array(Image.open(os.path.join(bg_mask_dir, file_name + '.JPEG')))\n",
    "\n",
    "        #if not bg_mask.shape[0] == bg_img.shape[0] and bg_mask.shape[1] == bg_img.shape[1]:\n",
    "            #bg_mask = cv2.resize(mask, (bg_img.shape[1], bg_img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # not sure why this is necessary, took from OccludedPascal3D+ code\n",
    "        #bg_bbox = bbt.from_numpy(bg_bbox, image_boundary=img.shape[0:2], sorts=('x0', 'y0', 'x1', 'y1'))\n",
    "\n",
    "        generate_composite_image(cate, bg_img, bg_w, bg_h, bg_bbox, save_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a9a55e4-662a-4975-bd90-b7d955d4ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cate:  bicycle\n",
      "Start cate:  bus\n",
      "Start cate:  car\n",
      "Start cate:  motorbike\n",
      "Start cate:  train\n"
     ]
    }
   ],
   "source": [
    "for cate in categories:\n",
    "    print('Start cate: ', cate)\n",
    "    tem = open('generating_record_%s_1030.txt' % cate, 'w')\n",
    "    file_list_ = open(bg_list_path % cate).readlines()\n",
    "    file_list_ = [tem.strip('\\n') for tem in file_list_]\n",
    "    bg_img_path_ = bg_img_path % cate\n",
    "    bg_anno_path_ = bg_anno_path % cate\n",
    "\n",
    "    generate_dataset(cate, file_list_, bg_img_path_, bg_anno_path_, save_img_path, save_anno_path, tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180a028-a765-41f5-939b-435577662e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibCom Environment",
   "language": "python",
   "name": "libcom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
