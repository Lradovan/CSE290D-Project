{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5f1599-c45b-432f-a660-7c09ae278506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.20.0 requires protobuf<4,>=3.12, but you have protobuf 4.25.5 which is incompatible.\n",
      "mediapipe 0.10.11 requires protobuf<4,>=3.11, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/envs/Libcom/lib/python3.8/site-packages (1.72.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-aiplatform) (2.0.6)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-aiplatform) (2.23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-aiplatform) (4.25.5)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-aiplatform) (3.27.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-aiplatform) (2.9.2)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-aiplatform) (24.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-aiplatform) (1.25.0)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-aiplatform) (2.18.2)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-aiplatform) (1.13.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-aiplatform) (2.36.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.68.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: mediapipe in /opt/conda/envs/Libcom/lib/python3.8/site-packages (0.10.11)\n",
      "Requirement already satisfied: jax in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from mediapipe) (0.4.13)\n",
      "Requirement already satisfied: absl-py in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from mediapipe) (3.7.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from mediapipe) (1.24.4)\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from mediapipe) (1.10.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: jaxlib in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from mediapipe) (0.4.13)\n",
      "Collecting protobuf<4,>=3.11\n",
      "  Using cached protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from jax->mediapipe) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from jax->mediapipe) (8.5.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from jax->mediapipe) (1.9.1)\n",
      "Requirement already satisfied: opt-einsum in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax->mediapipe) (3.21.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from matplotlib->mediapipe) (10.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from matplotlib->mediapipe) (4.54.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from matplotlib->mediapipe) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from matplotlib->mediapipe) (6.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from matplotlib->mediapipe) (3.1.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/envs/Libcom/lib/python3.8/site-packages (from torch->mediapipe) (4.12.2)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.5\n",
      "    Uninstalling protobuf-4.25.5:\n",
      "      Successfully uninstalled protobuf-4.25.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\n",
      "Successfully installed protobuf-3.20.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U google-generativeai\n",
    "%pip install google-cloud-aiplatform\n",
    "%pip install --upgrade -q google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
    "%pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "925cd4d6-d1fa-4919-8144-1d3115dd7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "import google.generativeai as genai\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/generative-language.retriever']\n",
    "\n",
    "def load_creds():\n",
    "    \"\"\"Converts `client_secret.json` to a credential object.\n",
    "\n",
    "    This function caches the generated tokens to minimize the use of the\n",
    "    consent screen.\n",
    "    \"\"\"\n",
    "    creds = None\n",
    "    # The file token.json stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'client_secret.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "creds = load_creds()\n",
    "\n",
    "genai.configure(credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e355d98a-0d15-4d11-aa89-27d4db8a3438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat', 'Bird', 'Equestrian', 'Dog', 'Person', 'Woman', 'Lamb', 'Plant', 'Baby', 'Foal', 'Birds', 'Martial Arts', 'Planter', 'Horse', 'Chicken', 'Sports', 'Cattle', 'Sheep', 'Cycling', 'Portrait', 'People', 'Man', 'Animal', 'Musician', 'Child', 'Horses', 'Beach', 'Cow', 'Agriculture', 'Sculpture', 'Livestock', 'Toddler', 'Motorcycle', 'Plants', 'Girl', 'Owl', 'Police', 'Children', 'Puppy', 'Elephant', 'Aviation', 'Horseback riding', 'Flamingo', 'Parking', 'Boy', 'Flowers', 'Medical', 'Fashion']\n",
      "defaultdict(<class 'list'>, {'Cat': [0, 6, 9, 11, 17, 58, 67, 69, 70, 77, 84, 90, 93, 103, 106, 131, 142, 143, 153, 173, 193, 247, 265, 274, 277, 286, 325, 326, 332, 345, 356, 361, 365, 369, 375, 404, 410, 413, 421, 426, 434, 435, 439, 448, 460, 461, 472, 477, 481, 482, 486, 490, 491, 493, 494, 496, 500], 'Bird': [1, 4, 16, 19, 29, 30, 32, 37, 38, 41, 42, 45, 46, 50, 53, 59, 71, 72, 80, 83, 99, 109, 112, 113, 118, 125, 130, 133, 149, 154, 160, 161, 163, 164, 168, 169, 170, 177, 181, 186, 199, 200, 201, 205, 210, 211, 212, 217, 218, 219, 229, 246, 263, 264, 267, 269, 276, 282, 292, 300, 307, 309, 320, 324, 328, 338, 339, 340, 347, 348, 352, 370, 372, 385, 388, 395, 400, 405, 409, 415, 418, 422, 423, 438, 451, 457, 466, 467, 487], 'Equestrian': [2, 204], 'Dog': [3, 8, 14, 18, 22, 23, 78, 81, 86, 89, 102, 119, 121, 123, 124, 126, 129, 134, 137, 155, 156, 167, 171, 175, 184, 187, 188, 191, 192, 203, 215, 220, 222, 230, 231, 236, 237, 249, 255, 260, 271, 283, 287, 289, 290, 291, 294, 306, 314, 329, 330, 334, 335, 341, 342, 346, 350, 351, 358, 362, 363, 371, 374, 378, 381, 384, 386, 387, 396, 398, 420, 440, 441, 442, 444, 447, 453, 454, 455, 458, 459, 464, 475, 476, 478, 484, 489, 499], 'Person': [5, 7, 20, 26, 35, 40, 51, 61, 63, 75, 82, 94, 95, 100, 105, 132, 135, 140, 145, 176, 178, 216, 221, 225, 239, 250, 251, 252, 253, 254, 272, 273, 296, 302, 303, 304, 305, 310, 313, 318, 331, 337, 353, 359, 390, 393, 401, 402, 403, 406, 411, 416, 417, 427, 445, 470, 473, 492], 'Woman': [10, 245], 'Lamb': [12, 152, 158, 174, 189], 'Plant': [13, 87, 139, 157, 182, 197, 198, 241, 248, 258, 284, 285, 366, 376, 377, 399, 407, 408, 436, 488, 495], 'Baby': [15, 74, 194, 397, 480], 'Foal': [21, 24, 317], 'Birds': [25], 'Martial Arts': [27], 'Planter': [28], 'Horse': [31, 36, 47, 52, 66, 79, 88, 107, 114, 120, 136, 147, 148, 151, 172, 185, 195, 196, 206, 207, 213, 226, 227, 235, 288, 301, 315, 333, 349, 380, 383, 465, 468, 485, 497], 'Chicken': [33], 'Sports': [34, 56, 111, 117, 122, 224, 256, 355, 414], 'Cattle': [39, 60, 62, 104, 110, 127, 141, 144, 180, 190, 233, 266, 299, 316, 336, 364, 367, 373, 379, 431], 'Sheep': [43, 73, 91, 92, 128, 165, 209, 295, 321, 327, 360, 452, 462, 471, 483], 'Cycling': [44, 65, 98, 412, 419], 'Portrait': [48, 49, 319, 391, 463], 'People': [54, 57, 64, 223, 368, 392, 428, 432, 474], 'Man': [55, 275, 446], 'Animal': [68, 101, 138, 183, 228, 232, 234, 270, 298, 357, 394, 443, 479], 'Musician': [76], 'Child': [96], 'Horses': [97, 389], 'Beach': [108], 'Cow': [115, 146, 150, 159, 166, 179, 202, 208, 214, 244, 268, 293, 322, 344, 433], 'Agriculture': [116, 430], 'Sculpture': [238], 'Livestock': [240, 343, 498], 'Toddler': [242], 'Motorcycle': [243, 259], 'Plants': [257], 'Girl': [261], 'Owl': [262, 354, 456], 'Police': [278, 279, 280, 449], 'Children': [281], 'Puppy': [297, 424], 'Elephant': [311], 'Aviation': [312], 'Horseback riding': [323], 'Flamingo': [382], 'Parking': [425], 'Boy': [429], 'Flowers': [437], 'Medical': [450], 'Fashion': [469]})\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_labels():\n",
    "    labels = defaultdict(list)\n",
    "    \n",
    "    with open('foreground_labels_small.csv', 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        # print(csv_reader.to_list())\n",
    "        first_row = True\n",
    "        for row in csv_reader:\n",
    "            if first_row:\n",
    "                first_row = False\n",
    "                continue\n",
    "            # print(row)\n",
    "            labels[row[1]].append(int(row[0]))\n",
    "            # break\n",
    "    return labels          \n",
    "            \n",
    "    # print(list(labels))\n",
    "output = get_labels()\n",
    "print(list(output.keys()))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76451d90-caac-4224-9f14-bba56cdc4455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x332 at 0x7F4858FE1AC0>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'google.generativeai' has no attribute 'GenerativeModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prompt)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# response = model.generate_content([prompt, skier_image])\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# print(response)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mfos\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m skier_image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/srv/PASCAL3D+_release1.1/Images/bus_imagenet/n02924116_10146.JPEG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(skier_image)\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mgenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerativeModel\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# # prompt = \"The goal is for you to go through a list of foreground objects, and select which one is the most realistic to cover the object in the image provided. The list of foreground objects are: [car, cat, dog, bird, bus, baby, tree]. You are forced to choose an option, and it should be a one word answer.\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# # prompt = \"You will be a given a list of foreground objects, and you are suppsoe to choose a category from that list to cover the subject in the image provided. Your answer should be one category from the list provided and should be a one word answer. You have to make a selection, and cannot say no. The list is [car, cat, dog, bird, bus, baby, tree].\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will be a given a list of foreground objects, and you are suppsoe to choose a category from that list to cover the subject in the image provided. Your answer should be one category from the list provided and should be a one word answer. You have to make a selection, and cannot say no. The list is: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(label_titles)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'google.generativeai' has no attribute 'GenerativeModel'"
     ]
    }
   ],
   "source": [
    "# take in a background image, and return what foreground image to occlude\n",
    "import PIL.Image\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "def fos():\n",
    "    labels = get_labels()\n",
    "    label_titles = list(labels.keys())\n",
    "    # n02924116_10146.JPEG\n",
    "    skier_image = PIL.Image.open('/srv/PASCAL3D+_release1.1/Images/bus_imagenet/n02924116_10146.JPEG')\n",
    "    print(skier_image)\n",
    "    \n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "    # # prompt = \"The goal is for you to go through a list of foreground objects, and select which one is the most realistic to cover the object in the image provided. The list of foreground objects are: [car, cat, dog, bird, bus, baby, tree]. You are forced to choose an option, and it should be a one word answer.\"\n",
    "    # # prompt = \"You will be a given a list of foreground objects, and you are suppsoe to choose a category from that list to cover the subject in the image provided. Your answer should be one category from the list provided and should be a one word answer. You have to make a selection, and cannot say no. The list is [car, cat, dog, bird, bus, baby, tree].\"\n",
    "    prompt = \"You will be a given a list of foreground objects, and you are suppsoe to choose a category from that list to cover the subject in the image provided. Your answer should be one category from the list provided and should be a one word answer. You have to make a selection, and cannot say no. The list is: \" + str(label_titles)\n",
    "    print(prompt)\n",
    "    # response = model.generate_content([prompt, skier_image])\n",
    "    # print(response)\n",
    "\n",
    "print(fos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8bb579-b79e-4a69-bfe0-50a0f0dcbb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "'''\n",
    "Important paths\n",
    "'''\n",
    "path_to_original_pascal3dp = '/srv/PASCAL3D+_release1.1/'\n",
    "\n",
    "small_occluder_path = '/srv/occluder_libs_test_small.npz'\n",
    "medium_occluder_path = '/srv/occluder_libs_test_medium.npz'\n",
    "large_occluder_path = '/srv/occluder_libs_test_large.npz'\n",
    "\n",
    "# just for now...\n",
    "occluder_path = '/srv/occluder_libs_test_low.npz'\n",
    "\n",
    "bg_list_path = path_to_original_pascal3dp + 'Image_sets/%s_imagenet_val.txt'\n",
    "bg_img_path = path_to_original_pascal3dp + 'Images/%s_imagenet'\n",
    "bg_anno_path = path_to_original_pascal3dp + 'Annotations/%s_imagenet'\n",
    "bg_mask_path = path_to_original_pascal3dp + 'obj_mask/%s'\n",
    "\n",
    "path_save = './results'\n",
    "save_img_path = path_save + '/images'\n",
    "save_anno_path = path_save + '/annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21f821bb-27fa-4292-9d86-181f90d27a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['bicycle', 'bus', 'car', 'motorbike', 'train']\n",
    "\n",
    "occlusion_ranges = {\n",
    "    \"low\": (0.2, 0.4),\n",
    "    \"medium\": (0.4, 0.6),\n",
    "    \"high\": (0.6, 0.8)\n",
    "}\n",
    "\n",
    "dataset = {\"low\": [], \"medium\": [], \"high\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f00d29f1-e78a-4b3e-bf65-5f2da434fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def load_one_annotation(anno_path):\n",
    "    a = scipy.io.loadmat(anno_path)\n",
    "    # I added the astype int here....\n",
    "    bbox_ = a['record'][0][0][1][0][0][1][0].astype(int)\n",
    "    w = a['record']['size'][0][0][0][0][0]\n",
    "    h = a['record']['size'][0][0][0][0][1]\n",
    "    num_obj = len(a['record'][0][0][1][0])\n",
    "    return w, h, bbox_, num_obj != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1c62389-e92d-470f-b1a3-86e1b646d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get overlap percentage based on bounding boxes\n",
    "'''\n",
    "def overlap_ratio(occluder_bb, occludee_bb):\n",
    "\n",
    "    #top left and bottom right points\n",
    "    occluder_x1, occluder_y1, occluder_x2, occluder_y2 = occluder_bb\n",
    "    occludee_x1, occludee_y1, occludee_x2, occludee_y2 = occludee_bb\n",
    "\n",
    "    # area of the foreground object\n",
    "    occludee_area = (occludee_x2 - occludee_x1) * (occludee_y2 - occludee_y1)\n",
    "\n",
    "    # area of the background object being covered by the foreground object\n",
    "    overlap_area = max(0, min(occludee_x2, occluder_x2) - max(occludee_x1, occluder_x1)) * max(0, min(occludee_y2, occluder_y2) - max(occludee_y1, occluder_y1))\n",
    "\n",
    "    # overlap over the total background object area\n",
    "    return overlap_area / occludee_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e96a0873-b634-49dd-a8e1-1965c12dfb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "'''\n",
    "Get a list of randomly chosen bounding boxes to occlude the background object above some threshold\n",
    "This can be improved if we know the foreground image has to be some base scale to allow for above threshold occlusion\n",
    "'''\n",
    "def get_bbox_list(bg_bbox, fg_mask, bg_w, bg_h, fg_w, fg_h):\n",
    "\n",
    "    random.seed(time.time())\n",
    "\n",
    "    bboxes = []\n",
    "    occludee_x1 = bg_bbox[0]\n",
    "    occludee_y1 = bg_bbox[1] \n",
    "    occludee_x2 = bg_bbox[2]\n",
    "    occludee_y2 = bg_bbox[3]\n",
    "    num_boxes = 20\n",
    "    \n",
    "    for _ in range(num_boxes):\n",
    "\n",
    "        occluder_x1 = random.randint(max(0, occludee_x1 - fg_w), occludee_x2) # overlapping in the x-direction\n",
    "        occluder_y1 = random.randint(max(0, occludee_y1 - fg_h), occludee_y2) # overlapping in the y-direction\n",
    "\n",
    "        # TODO: Fix so doesnt exceed background image\n",
    "        \n",
    "        occluder_x2 = occluder_x1 + fg_w\n",
    "        occluder_y2 = occluder_y1 + fg_h\n",
    "\n",
    "        if occluder_x2 > bg_w or occluder_y2 > bg_h:\n",
    "            continue\n",
    "\n",
    "        occluder_bb = [occluder_x1, occluder_y1, occluder_x2, occluder_y2]\n",
    "        occluded_ratio = overlap_ratio(occluder_bb, bg_bbox)\n",
    "\n",
    "        if occluded_ratio >= .20:\n",
    "            bboxes.append((occluded_ratio, [occluder_x1, occluder_y1, occluder_x2, occluder_y2]))\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5bce983-70a5-4382-b39f-f3c477f6ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "returns the score, composite image, and compositive mask. \n",
    "num scales is the number of different foreground scales to try.\n",
    "'''\n",
    "from libcom import OPAScoreModel\n",
    "\n",
    "def get_optimal_location(fg_img, fg_mask, bg_img, bg_w, bg_h, bg_bbox, num_scales):\n",
    "\n",
    "    net = OPAScoreModel(device=0, model_type='SimOPA')\n",
    "    cache_dir = './cache'\n",
    "\n",
    "    # from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "    scaled_fg_dir, scaled_mask_dir, csv_path = prepare_multi_fg_scales(cache_dir, fg_img, fg_mask, bg_img, 16)\n",
    "\n",
    "    score = 0\n",
    "    ratio = 0\n",
    "    optimal_bbox = None\n",
    "    best_fg = None\n",
    "    best_mask = None\n",
    "    best_comp = None \n",
    "    best_comp_mask = None\n",
    "    \n",
    "    with open(csv_path, mode='r', newline='') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            fg_name   = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            mask_name = '{}_{}_{}_{}.jpg'.format(row[\"fg_name\"].split(\".\")[0],row[\"bg_name\"].split(\".\")[0],int(row[\"newWidth\"]),int(row[\"newHeight\"]))\n",
    "            fg_w = int(row['newWidth'])\n",
    "            fg_h = int(row['newHeight'])\n",
    "\n",
    "            # why are we doing this...\n",
    "            bg_img    = read_image_pil(bg_img)\n",
    "            bbox_list = get_bbox_list(bg_bbox, fg_mask, bg_w, bg_h, fg_w, fg_h)\n",
    "\n",
    "            fg_img = os.path.join(scaled_fg_dir, fg_name)\n",
    "            fg_mask = os.path.join(scaled_mask_dir, mask_name)\n",
    "\n",
    "            for occ_ratio, bbox in bbox_list:\n",
    "                comp, comp_mask = get_composite_image(fg_img, fg_mask, bg_img, bbox)\n",
    "                bbox_score = net(comp, comp_mask)\n",
    "                if bbox_score > score:\n",
    "                    best_fg = fg_img\n",
    "                    best_mask = fg_mask\n",
    "                    optimal_bbox = bbox\n",
    "                    best_comp = comp\n",
    "                    best_comp_mask = comp_mask\n",
    "                    score = bbox_score\n",
    "                    ratio = occ_ratio\n",
    "\n",
    "        return score, ratio, best_fg, best_mask, optimal_bbox, best_comp, best_comp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "268561c1-e56f-4a6e-96ec-a111b075838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "'''\n",
    "Get a random occluder and correspondiong mask\n",
    "'''\n",
    "def get_occluder():\n",
    "    data = np.load(occluder_path, allow_pickle=True)\n",
    "\n",
    "    random.seed(time.time())\n",
    "\n",
    "    os.makedirs('./occluders', exist_ok=True)\n",
    "    \n",
    "    i = random.randint(0, len(data['images']))\n",
    "    occ_img = f'./occluders/fg_img_{i}.jpg'\n",
    "    occ_mask = f'./occluders/fg_mask_{i}.png'\n",
    "\n",
    "    image = data['images'][i]\n",
    "    mask = data['masks'][i]\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "        \n",
    "    cv2.imwrite(occ_img, image)\n",
    "    cv2.imwrite(occ_mask, mask)\n",
    "\n",
    "    return occ_img, occ_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99bea1-73c9-4c5a-b7ef-7dc4643f328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fos("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3138f32b-47d2-44d2-9dff-51d5deb6463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libcom import color_transfer\n",
    "from libcom.utils.process_image import *\n",
    "from libcom.utils.environment import *\n",
    "from libcom import OPAScoreModel\n",
    "from libcom import get_composite_image\n",
    "from libcom.utils.process_image import make_image_grid\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image\n",
    "from libcom.fopa_heat_map.source.prepare_multi_fg_scales import prepare_multi_fg_scales\n",
    "from libcom import Mure_ObjectStitchModel\n",
    "from libcom import ControlComModel\n",
    "import json\n",
    "\n",
    "def generate_composite_image(cate, bg_img, bg_w, bg_h, bg_bbox, save_img_path):\n",
    "\n",
    "    net = Mure_ObjectStitchModel(device=0, sampler='plms')\n",
    "\n",
    "    # maybe a list isnt necessary here? They do one anntotation for each of the occlusion ratios in OccludedPascal3D+\n",
    "    annotation = {}\n",
    "\n",
    "    # fg_mask is a path to an image here.... but bg_mask is a numpy array!\n",
    "    fg_img, fg_mask = get_occluder()\n",
    "\n",
    "    occluder_path = fg_img\n",
    "\n",
    "    img_id = bg_img.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    score, ratio, fg_img, fg_mask, bbox, comp, comp_mask = get_optimal_location(fg_img, fg_mask, bg_img, bg_w, bg_h, bg_bbox, num_scales=16)\n",
    "\n",
    "    # x1, y1, x2, y2 = bg_bbox\n",
    "\n",
    "    annotation['box'] = bg_bbox.tolist() \n",
    "    annotation['ratio'] = ratio\n",
    "    annotation['occluder_box'] = bbox\n",
    "    annotation['occluder_path'] = occluder_path\n",
    "    annotation['source'] = bg_img\n",
    "    annotation['cate'] = cate\n",
    "\n",
    "    # write to a directory based on the level of occlusion\n",
    "    occlusion_level = None\n",
    "    for range_label, (min_occ, max_occ) in occlusion_ranges.items():\n",
    "        if min_occ <= ratio <= max_occ:\n",
    "            occlusion_level = range_label\n",
    "            \n",
    "    if(score):\n",
    "        res, show_fg_img = net(bg_img, [fg_img], [fg_mask], bbox, sample_steps=25, num_samples=3)\n",
    "\n",
    "        # Convert and write JSON object to file\n",
    "        with open(f'{save_anno_path}/{occlusion_level}/{img_id}.json', \"w\") as outfile: \n",
    "            json.dump(annotation, outfile)\n",
    "        \n",
    "        # TODO: find the best result in res, instead of just taking the last sample!!!!\n",
    "        cv2.imwrite(f'{save_img_path}/{occlusion_level}/{img_id}.jpg', res[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b12fc27-ed49-4054-b70e-f934f343fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import BboxTools as bbt\n",
    "import os\n",
    "\n",
    "# the only reason we have bg_mask_dir is in case we need it for segmentation masks...\n",
    "def generate_dataset(cate, file_list, bg_img_dir, bg_anno_dir, save_img_dir, save_anno_dir, record_file):\n",
    "\n",
    "    os.makedirs(save_img_dir, exist_ok=True)\n",
    "    os.makedirs(save_anno_dir, exist_ok=True)\n",
    "\n",
    "    # make a different directory for each range\n",
    "    for range_label in occlusion_ranges.keys():\n",
    "        os.makedirs(save_img_dir + \"/\" + range_label, exist_ok=True)\n",
    "        os.makedirs(save_anno_dir + \"/\" + range_label, exist_ok=True)\n",
    "    \n",
    "    for file_name in file_list[9:10]:\n",
    "        bg_w, bg_h, bg_bbox, flag_ = load_one_annotation(os.path.join(bg_anno_dir, file_name + '.mat'))\n",
    "\n",
    "        if flag_:\n",
    "            record_file.write('Skipped %s for multi objects\\n' % file_name)\n",
    "            continue\n",
    "\n",
    "        bg_img = os.path.join(bg_img_dir, file_name + '.JPEG')\n",
    "        # bg_mask = np.array(Image.open(os.path.join(bg_mask_dir, file_name + '.JPEG')))\n",
    "\n",
    "        #if not bg_mask.shape[0] == bg_img.shape[0] and bg_mask.shape[1] == bg_img.shape[1]:\n",
    "            #bg_mask = cv2.resize(mask, (bg_img.shape[1], bg_img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # not sure why this is necessary, took from OccludedPascal3D+ code\n",
    "        #bg_bbox = bbt.from_numpy(bg_bbox, image_boundary=img.shape[0:2], sorts=('x0', 'y0', 'x1', 'y1'))\n",
    "\n",
    "        generate_composite_image(cate, bg_img, bg_w, bg_h, bg_bbox, save_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a9a55e4-662a-4975-bd90-b7d955d4ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cate:  bicycle\n",
      "Start cate:  bus\n",
      "Start cate:  car\n",
      "Start cate:  motorbike\n",
      "Start cate:  train\n"
     ]
    }
   ],
   "source": [
    "for cate in categories:\n",
    "    print('Start cate: ', cate)\n",
    "    tem = open('generating_record_%s_1030.txt' % cate, 'w')\n",
    "    file_list_ = open(bg_list_path % cate).readlines()\n",
    "    file_list_ = [tem.strip('\\n') for tem in file_list_]\n",
    "    bg_img_path_ = bg_img_path % cate\n",
    "    bg_anno_path_ = bg_anno_path % cate\n",
    "\n",
    "    generate_dataset(cate, file_list_, bg_img_path_, bg_anno_path_, save_img_path, save_anno_path, tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180a028-a765-41f5-939b-435577662e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
